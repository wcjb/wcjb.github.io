<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>傅立叶变换</title>
    <url>/posts/684f5543/</url>
    <content><![CDATA[<p>  希尔伯特空间是一个完备的内积空间，其标准正交函数系，直观来看就是向量空间中<code>基</code>的延伸。其为基于任意正交系上的多项式表示的傅立叶级数和傅立叶变换提供了一种有效的表述方式，而这也是泛函分析的核心概念之一。下文中我们将通过希尔伯特空间的标准正交函数系推导周期函数和有限区间上函数的傅立叶级数表示，并进一步推出傅里叶积分来表示无穷区间的非周期函数，最后引入复数形式的傅立叶积分，引出傅立叶变换。在这一系列推导中，鉴于篇幅，主动略去了一些比较关键的部分，比如<span class="math inline">\(f(x)\)</span>可积性及级数收敛性的讨论，有兴趣的读者可以在了解大致原理后，进行细致的理论推导以作补充。为了便于理解希尔伯特空间的概念，引用维基百科中的定义：
<span id="more"></span></p>
<blockquote>
<p>  在数学里，希尔伯特空间（英语：Hilbert
space）即完备的内积空间，也就是一个带有内积的完备矢量空间。内积的构造推广了欧几里得空间的距离和角的概念；完备则确保了其上所有的柯西序列会收敛到此空间里的一点，从而微积分中的许多概念都可以推广到希尔伯特空间中。希尔伯特空间为基于任意正交坐标系上的多项式表示的傅立叶级数和傅立叶变换提供了一种有效的表述方式，而这也是泛函分析的核心概念之一,另外希尔伯特空间也是量子力学的重要数学基础之一。</p>
</blockquote>
<h1 id="希尔伯特空间">希尔伯特空间</h1>
<p>  若无限维<code>酉空间</code><span class="math inline">\(V\)</span>中每个基本序列收敛于V中的元素，则称<span class="math inline">\(V\)</span>是<code>完备</code>的。一个完备的无限维酉空间称为希尔伯特空间又称为<span class="math inline">\(H\)</span>空间。在<span class="math inline">\(n\)</span>维空间中矢量被定义为<span class="math inline">\((f_1,f_2,\cdots,f_n)\)</span>,在无限维空间中矢量被定义为<span class="math inline">\(t\)</span>从<span class="math inline">\(a\)</span>变换到<span class="math inline">\(b\)</span>的函数<span class="math inline">\(f(t)\)</span>。在希尔伯特空间中矢量的加法和乘法定义为函数的加法与函数和数的乘法。</p>
<ul>
<li><p>内积</p>
<p>​ 对于<span class="math inline">\(f,g \in
H\)</span>,则二者的内积定义为： <span class="math display">\[
(f,g) = \int_{a}^{b}f(t)g(t)d t
\tag{1}
\]</span></p></li>
<li><p>度量</p>
<ul>
<li>对于<span class="math inline">\(f(t)\in H\)</span>,其长度定义为：
<span class="math display">\[
L_H=\sqrt{\int_{a}^{b}f^2(t)dt}\tag{2}
\]</span></li>
</ul></li>
<li><p>若<span class="math inline">\(f(t),g(t)\in
H\)</span>则二者之间的距离定义为： <span class="math display">\[
D_H=\sqrt{\int_{a}^{b}(f(t)-g(t))^2dt}\tag{3}
\]</span> 直观来看就是两个函数的均方差，就是以均方差来作为<span class="math inline">\(H\)</span>空间的距离的度量。</p></li>
<li><p>若<span class="math inline">\(f(t),g(t)\in
H\)</span>,则二者的夹角定义为： <span class="math display">\[
\Omega =
\arccos{\frac{\int_{a}^{b}f(t)g(t)dt}{\sqrt{\int_{a}^{b}f^2(t)}\sqrt{\int_{a}^{b}g^2(t)dt}}}\tag{4}
\]</span></p></li>
<li><p>正交函数系</p>
<ul>
<li><p>若非零矢量<span class="math inline">\(f,g\in
H\)</span>的内积<span class="math inline">\((f,g)=0\)</span>，则由<span class="math inline">\(H\)</span>空间的夹角定义公式可知<span class="math inline">\(\Omega=\frac{\pi}{2}\)</span>,此时称矢量<span class="math inline">\(f,g\)</span>正交。</p></li>
<li><p>若<span class="math inline">\(f_i \in
H,i=1,\cdots,n\)</span>且两两正交，设 <span class="math display">\[
f(x) = \sum\limits_{i=1}^{n}f_{i}(x)\tag{5}
\]</span> 则有 <span class="math display">\[
L_{f(x)}^2=\sum\limits_{i=1}^{n}L_{f_{i}(x)}^2\tag{6}
\]</span> 由<span class="math inline">\(H\)</span>空间长度和正交的定义可推出： <span class="math display">\[
L_{f(x)}^{2}=\int_{a}^bf^2(x)dx=\int_{a}^b[\sum\limits_{i=0}^{n}f_i(x)]^2dx=\int_{a}^b[\sum\limits_{i=0}^{n}
f_i^2(x)]dx=\sum\limits_{i=0}^{n}[\int_{a}^bf_i^2(x)dx]\tag{7}
\]</span> 上述积分都是指勒贝格积分有意义。</p></li>
<li><p>若函数系<span class="math inline">\(\phi_i(x)\in
H,i=1,\cdots,n,\cdots\)</span>中任意两个函数相互正交，即 <span class="math display">\[
\int_{a}^{b}\phi_i(x)\phi_j(x)dx=0（i\neq j）\tag{8}
\]</span> 则称这个函数系为正交函数系，若还满足 <span class="math display">\[
\int_{a}^{b}\phi_{k}^2(x)dx=1（k \in 1,\cdots,n,\cdots）\tag{9}
\]</span> 则称此函数系为标准正交系。</p></li>
</ul></li>
<li><p>依标准正交函数系的分解</p>
<p>​ 若在<span class="math inline">\(H\)</span>空间中给定一个完备的标准正交函数系<span class="math inline">\(\phi_1(x),\phi_2(x),\cdots,\phi_n(x),\cdots\)</span>（即不可能再加一个不恒为零的函数与系中的一切函数正交），则对于任意函数<span class="math inline">\(f(x)\)</span>都可根据这个标准正交函数系展开成级数（平均收敛）：</p>
<p><span class="math display">\[
f(x)=\sum\limits_{i=1}^{\infty}a_i\phi_i(x)=a_1\phi_1(x)+a_2\phi_2(x)+\cdots+a_n\phi_n(x)+\cdots\tag{10}
\]</span> <span class="math inline">\(a_n\)</span>为<span class="math inline">\(\phi_n(x)\)</span>在这个标准正交函数系上的投影：</p></li>
</ul>
<p><span class="math display">\[
  a_n = (f,\phi_n)=\int_{a}^{b}f(x)\phi_n(x)dx（n=1,2,\cdots）\tag{11}
\]</span> 很容易证明 <span class="math display">\[
  \int_{a}^{b}f^2(x)dx=\sum\limits_{i=1}^{\infty}a^2_i\tag{12}
\]</span> 代表<span class="math inline">\(H\)</span>空间中矢量的长度平方等于该矢量在完备的标准正交系中的矢量上的投影平方和。</p>
<h1 id="傅立叶级数">傅立叶级数</h1>
<p>  希尔伯特空间是有限维欧几里得空间的推广，与欧几里得空间相同，希尔伯特空间也是内积空间，也有距离和角的概念，并且不同于欧几里得空间，<span class="math inline">\(H\)</span>空间具有<code>完备性</code>：希尔伯特空间内的所有的<code>柯西列</code>会收敛到一点。因此微积分中的大部分概念可无障碍推广至希尔伯特空间中。希尔伯特空间提供了一个很强大理论工具：<strong>对于<span class="math inline">\(H\)</span>空间中的任意函数<span class="math inline">\(f(x)\)</span>都可以由<span class="math inline">\(H\)</span>空间中完备的标准正交函数系展开成级数</strong>。也就是说，可以通过一个标准正交函数系去逼近一个任意函数（这些函数都是基于希尔伯特空间的）。</p>
<h2 id="三角函数系">三角函数系</h2>
<p>  基于上述的讨论，接下来讨论如何通过一个标准正交函数系来展开任意函数。基于标准正交函数的定义，直观来看，三角函数系似乎完美的切合，对于三角函数系
<span class="math display">\[
1,cos(x),sin(x),\cdots,cos(kx),sin(kx),\cdots\tag{13}
\]</span> 由于 <span class="math display">\[
\int_{-\pi}^{\pi}1*cos(kx)\mathrm{d}x=\frac{2}{k}\int_{0}^{\pi}cos(kx)\mathrm{d}
kx =\frac{2}{k}sin(kx)|^{\pi}_{0}=0（k=1,2,3,\dots）\tag{14}
\]</span> 又由奇函数的性质直接得到（15）（16）定积分等式成立： <span class="math display">\[
\int_{-\pi}^{\pi}1*sin(kx)\mathrm{d}x=0（k=1,2,3,\dots）\tag{15}
\]</span></p>
<p><span class="math display">\[
\int_{-\pi}^{\pi}sin(kx)cos(nx)\mathrm{d}x=0（k，n=1,2,3,\dots；k\neq
n）\tag{16}
\]</span></p>
<p>又： <span class="math display">\[
\int_{-\pi}^{\pi}cos(kx)cos(nx)\mathrm{d}x\overset{积化和差}{=}\int_{-\pi}^{\pi}\frac{1}{2}[cos(k+n)x+cos(k-n)x]\mathrm{d}x=0（k，n=1,2,3,\dots；k\neq
n）\tag{17}
\]</span> 同理得到： <span class="math display">\[
\int_{-\pi}^{\pi}sin(kx)sin(nx)\mathrm{d}x\overset{积化和差}{=}\int_{-\pi}^{\pi}-\frac{1}{2}[cos(k+n)x-cos(k-n)x]\mathrm{d}x=0（k，n=1,2,3,\dots；k\neq
n）\tag{18}
\]</span> 于是得到三角函数系（13）在<span class="math inline">\([-\pi,\pi]\)</span>是一个正交函数系，但是，细心的读者可能发现，三角函数系（13）并不是一个标准正交函数系，为此基于（13）构造三角函数系
<span class="math display">\[
\frac{1}{\sqrt{2\pi}},\frac{cos(x)}{\sqrt{\pi}},\frac{sin(x)}{\sqrt{\pi}},\cdots,\frac{cos(kx)}{\sqrt{\pi}},\frac{sin(kx)}{\sqrt{\pi}},\cdots\tag{19}
\]</span>
显然，三角函数系（20）是一个正交函数系，下面进一步证明该函数系是一个标准正交函数系，则只需证明对于该函数系任意函数有（9）式成立即可：
<span class="math display">\[
\int_{-\pi}^{\pi}(\frac{1}{\sqrt{2\pi}})^2\mathrm{d}x=\frac{1}{2\pi}x|_{-\pi}^{\pi}=1\tag{20}
\]</span></p>
<p><span class="math display">\[
\int_{-\pi}^{\pi}(\frac{cos(kx)}{\sqrt{\pi}})^2\mathrm{d}x=\int_{-\pi}^{\pi}\frac{cos^2(kx)}{\pi}\mathrm{d}x\overset{三角降幂公式}{=}\int_{-\pi}^{\pi}\frac{1+cos(2kx)}{2\pi}\mathrm{d}x=(\frac{1}{2\pi}x+\frac{1}{4k\pi}sin(k\pi))｜_{-\pi}^{\pi}=1\\\tag{21}
\]</span></p>
<p><span class="math display">\[
\int_{-\pi}^{\pi}(\frac{sin(kx)}{\sqrt{\pi}})^2\mathrm{d}x=\int_{-\pi}^{\pi}\frac{sin^2(kx)}{\pi}\mathrm{d}x\overset{三角降幂公式}{=}\int_{-\pi}^{\pi}\frac{1-cos(2kx)}{2\pi}\mathrm{d}x=(\frac{1}{2\pi}x-\frac{1}{4k\pi}sin(k\pi))｜_{-\pi}^{\pi}=1\tag{22}
\]</span></p>
<p>由（20）（21）（22）三式可得，三角函数系（19）为希尔伯特空间下的标准正交函数系。则任意定义在<span class="math inline">\([-\pi,\pi]\)</span>的函数<span class="math inline">\(f(x)\)</span>有： <span class="math display">\[
f(x)=c_0\frac{1}{\sqrt{2\pi}}+a_0\frac{cos(x)}{\sqrt{\pi}}+b_0\frac{sin(x)}{\sqrt{\pi}}+\dots+a_k\frac{cos(kx)}{\sqrt{\pi}}+b_k\frac{sin(kx)}{\sqrt{\pi}}+\dots\tag{23}
\]</span> 整理得： <span class="math display">\[
f(x)=c_0\frac{1}{\sqrt{2\pi}}+\sum_{i=1}^{\infty}a_i\frac{cos(ix)}{\sqrt{\pi}}+\sum_{i=0}^{\infty}b_i\frac{sin(ix)}{\sqrt{\pi}}=c_0\frac{1}{\sqrt{2\pi}}+\sum_{i=1}^{\infty}(a_i\frac{cos(ix)}{\sqrt{\pi}}+b_i\frac{sin(ix)}{\sqrt{\pi}})\tag{24}
\]</span> 此时，只需确定系数<span class="math inline">\(c_0,a_i,b_i（i=1,2,3,\dots）\)</span>即可得到<span class="math inline">\(f(x)\)</span>在在<span class="math inline">\([-\pi,\pi]\)</span>的级数展开形式：</p>
<blockquote>
<p><span class="math inline">\(c_0\)</span>:</p>
<p>  对等式（24）两边同时求积分得到： <span class="math display">\[
\int_{-\pi}^{\pi}f(x)\mathrm{d}x =
\int_{-\pi}^{\pi}c_0\frac{1}{\sqrt{2\pi}}\mathrm{d}x+\int_{-\pi}^{\pi}\sum_{i=1}^{\infty}(a_i\frac{cos(ix)}{\sqrt{\pi}}+b_i\frac{sin(ix)}{\sqrt{\pi}})\mathrm{d}x\tag{25}
\]</span> 结合（14）（15）（16）得到： <span class="math display">\[
\int_{-\pi}^{\pi}f(x)\mathrm{d}x =
\int_{-\pi}^{\pi}c_0\frac{1}{\sqrt{2\pi}}\mathrm{d}x+0=c_0\sqrt{2\pi}\tag{26}
\]</span> 求得: <span class="math display">\[
c_0 = \frac{1}{\sqrt{2\pi}}\int_{-\pi}^{\pi}f(x)\mathrm{d}x\tag{27}
\]</span> <span class="math inline">\(a_i\)</span>:</p>
<p>  结合（21）式，对等式（24）两边同乘<span class="math inline">\(cos(jx)\)</span>,得到： <span class="math display">\[
f(x)cos(jx)=c_0\frac{1}{\sqrt{2\pi}}cos(jx)+\sum_{i=1}^{\infty}(a_i\frac{cos(ix)cos(jx)}{\sqrt{\pi}}+b_i\frac{sin(ix)cos(jx)}{\sqrt{\pi}})（j=1,2,3,\dots）\tag{28}
\]</span> 同样对等式（30）两边同时求积分得到： <span class="math display">\[
\int_{-\pi}^{\pi}f(x)cos(jx)\mathrm{d}x=\color{#F00}{\int_{-\pi}^{\pi}c_0\frac{1}{\sqrt{2\pi}}cos(jx)\mathrm{d}x}+\color{#00F}{\sum_{i=1}^{\infty}\int_{-\pi}^{\pi}a_i\frac{cos(ix)cos(jx)}{\sqrt{\pi}}\mathrm{d}x}+\color{#F00}{\sum_{i=1}^{\infty}\int_{-\pi}^{\pi}b_i\frac{sin(ix)cos(jx)}{\sqrt{\pi}}\mathrm{d}x}\tag{29}
\]</span> 由（14）（16）式可知，等式（29）中两个红色定积分都为<span class="math inline">\(0\)</span>，对于蓝色定积分，由（17）（21）式可知，当且仅当<span class="math inline">\(i= j\)</span>的项积分为<span class="math inline">\(1\)</span>，其余项的积分都为<span class="math inline">\(0\)</span>，故： <span class="math display">\[
\int_{-\pi}^{\pi}f(x)cos(jx)\mathrm{d}x=\color{#00F}{\sum_{i=1}^{\infty}\int_{-\pi}^{\pi}a_i\frac{cos(ix)cos(jx)}{\sqrt{\pi}}\mathrm{d}x}=\color{#F00}{\sum_{i=1,i\neq
j
}^{\infty}\int_{-\pi}^{\pi}a_i\frac{cos(ix)cos(jx)}{\sqrt{\pi}}\mathrm{d}x}+\color{#0F0}{\int_{-\pi}^{\pi}a_j\frac{cos(jx)cos(jx)}{\sqrt{\pi}}\mathrm{d}x}\tag{30}
\]</span>
将蓝色部分的积分拆分为红色和绿色两部分积分之和（绿色积分为<span class="math inline">\(i=j\)</span>时），显然由（17）式红色部分积分仍旧为<span class="math inline">\(0\)</span>，由（21）式绿色部分积分为<span class="math inline">\(\sqrt{\pi}a_j\)</span>，进一步得到: <span class="math display">\[
a_i\overset{i=j}{=}a_j=\frac{1}{\sqrt{\pi}}\int_{-\pi}^{\pi}f(x)cos(ix)\mathrm{d}x\tag{31}
\]</span> <span class="math inline">\(b_i\)</span>:</p>
<p>  同上可得到： <span class="math display">\[
b_i=\frac{1}{\sqrt{\pi}}\int_{-\pi}^{\pi}f(x)sin(ix)\mathrm{d}x\tag{32}
\]</span></p>
</blockquote>
<h2 id="周期与非周期下的傅里叶级数">周期与非周期下的傅里叶级数</h2>
<p>  在上文中，已经求出了系数的表达式，将这些系数代入（24）式，整理得到：
<span class="math display">\[
\begin{aligned}
f(x)&amp;=c_0\frac{1}{\sqrt{2\pi}}+\sum_{i=1}^{\infty}(a_i\frac{cos(ix)}{\sqrt{\pi}}+b_i\frac{sin(ix)}{\sqrt{\pi}})\\
&amp;=（\frac{1}{\sqrt{2\pi}}\int_{-\pi}^{\pi}f(x)\mathrm{d}x）\frac{1}{\sqrt{2\pi}}+\sum_{i=1}^{\infty}[(\frac{1}{\sqrt{\pi}}\int_{-\pi}^{\pi}f(x)cos(ix)\mathrm{d}x)\frac{cos(ix)}{\sqrt{\pi}}+(\frac{1}{\sqrt{\pi}}\int_{-\pi}^{\pi}f(x)sin(ix)\mathrm{d}x)\frac{sin(ix)}{\sqrt{\pi}}]\\
&amp;=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)\mathrm{d}x+\sum_{i=0}^{\infty}[\color{#00F}{\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)cos(ix)\mathrm{d}x}
*
\color{#F0F}{cos(ix)}+\color{#00F}{\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)sin(ix)\mathrm{d}x}
* \color{#F0F}{sin(ix)}]
\end{aligned}
\]</span> 此时，令 <span class="math display">\[
\begin{aligned}
a_0&amp;=\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)\mathrm{d}x\\
a_n&amp;=\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)cos(nx)\mathrm{d}x\\
b_n&amp;=\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)sin(nx)\mathrm{d}x
\end{aligned}\tag{34}
\]</span> 得到： <span class="math display">\[
f(x) = \frac{a_0}{2}+\sum_{n=1}^{\infty}[a_icos(nx)+b_isin(nx)]\tag{35}
\]</span>
式（35）显然就是傅立叶级数。级数（35）的收敛性证明，涉及较多泛函分析的内容，在此不做展开，有时间在另开一篇文章说明，有兴趣的读者可以尝试一下证明。细心的读者可能注意到<span class="math inline">\(f(x)\)</span>的定义域是<span class="math inline">\([-\pi,\pi]\)</span>，那么如果对于任意周期<span class="math inline">\(T\)</span>，级数还成立吗？将定义域拓展到实数域后，级数（35）还成立吗？对此，下面进一步讨论。</p>
<h3 id="周期函数的傅立叶级数">周期函数的傅立叶级数</h3>
<p>  当<span class="math inline">\(f(x)\)</span>是一个周期为<span class="math inline">\(2\pi\)</span>的周期函数时，那么在区间<span class="math inline">\([-\pi,\pi]\)</span>中，作变换： <span class="math display">\[
x = \frac{2\pi}{2T}t=\frac{\pi}{T}t\tag{36}
\]</span> 则<span class="math inline">\(F(t)=f(\frac{\pi}{T}t),t \in
[-T,T]\)</span>，为周期<span class="math inline">\(2T\)</span>的周期函数，构造标准正交三角函数系：
<span class="math display">\[
\frac{1}{\sqrt{2T}},\frac{cos(x)}{\sqrt{T}},\frac{sin(x)}{\sqrt{T}},\cdots,\frac{cos(kx)}{\sqrt{T}},\frac{sin(kx)}{\sqrt{T}},\cdots\tag{37}
\]</span> 进一步得到此时的傅立叶系数： <span class="math display">\[
\begin{aligned}
a_0&amp;=\frac{1}{T}\int_{-T}^{T}f(x)\mathrm{d}x\\
a_n&amp;=\frac{1}{T}\int_{-T}^{T}f(x)cos(\frac{n\pi}{T}x)\mathrm{d}x\\
b_n&amp;=\frac{1}{T}\int_{-T}^{T}f(x)sin(\frac{n\pi}{T}x)\mathrm{d}x
\end{aligned}\tag{38}
\]</span> 则此时的傅立叶级数为： <span class="math display">\[
\color{#F00}{F(t) =
\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_icos(\frac{n\pi}{T}t)+b_isin(\frac{n\pi}{T}t)]}\tag{39}
\]</span>
因此，对于可积的任意周期函数，都能展开为对应的傅立叶级数，并且由于周期函数的特性，当定义域拓展到实数域时也是成立的。</p>
<h3 id="非周期函数的傅立叶积分">非周期函数的傅立叶积分</h3>
<p>  在更多情况下，需要处理非周期函数，对此比较直观的处理技巧是，将非周期函数视为周期为<span class="math inline">\(\infty\)</span>的周期函数，即<span class="math inline">\(2T \to +\infty\)</span>。设<span class="math inline">\(\xi(x)\)</span>是定义在<span class="math inline">\(R\)</span>上，并且在定义域绝对可积，<span class="math inline">\(\xi_T(x)\)</span>是<span class="math inline">\(\xi(x)\)</span>在有限区间<span class="math inline">\([-T,T]\)</span>上的截取，因为<span class="math inline">\(\xi_{T}(x)\)</span>可视为该有限区间上的周期函数，令<span class="math inline">\(\omega=\frac{2\pi}{2T},\)</span>则得到<span class="math inline">\(\xi_{T}(x)\)</span>的傅立叶级数为： <span class="math display">\[
\xi_{T}(x)=\frac{a_0}{2}+\sum_{n=1}^{\infty}[a_ncos(n\omega
x)+b_nsin(n\omega x)]\tag{40}
\]</span> 其中： <span class="math display">\[
\begin{aligned}
a_0&amp;=\frac{1}{T}\int_{-T}^{T}f(t)\mathrm{d}t\\
a_n&amp;=\frac{1}{T}\int_{-T}^{T}f(t)cos(n\omega t)\mathrm{d}t\\
b_n&amp;=\frac{1}{T}\int_{-T}^{T}f(t)sin(n \omega t)\mathrm{d}t
\end{aligned}\tag{41}
\]</span> 得到： <span class="math display">\[
\begin{aligned}
\xi_T(x)&amp;=\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t+\sum_{n=1}^{\infty}[\frac{1}{T}\int_{-T}^{T}f(t)cos(n\omega
t)\mathrm{d}tcos(n\omega x)+\frac{1}{T}\int_{-T}^{T}f(t)sin(n \omega
t)\mathrm{d}tsin(n\omega x)] \\
&amp;=\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t+\sum_{n=1}^{\infty}\frac{1}{T}\int_{-T}^{T}f(t)[cos(n\omega
t)cos(n\omega x)+sin(n \omega t)sin(n\omega x)]\mathrm{d}t \\
&amp;=\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t+\sum_{n=1}^{\infty}\frac{1}{T}\int_{-T}^{T}f(t)cos[n\omega(x-t)]\mathrm{d}t
\end{aligned}\tag{42}
\]</span></p>
<p>于是有： <span class="math display">\[
\xi(x)=\lim_{T \to \infty}\xi_{T}(x)=\lim_{T \to
\infty}\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t+\lim_{T \to
\infty}\sum_{n=1}^{\infty}\frac{1}{T}\int_{-T}^{T}f(t)cos[n\omega(x-t)]\mathrm{d}t\tag{43}
\]</span></p>
<p>对于（43）式的两个极限，接下来分别进行讨论：</p>
<blockquote>
<p>对于第一个极限：</p>
<p>  由于<span class="math inline">\(f(t)\)</span>在<span class="math inline">\(R\)</span>上绝对可积，则： <span class="math display">\[
\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t
\leq\frac{1}{2T}\int_{-\infty}^{\infty}|f(t)|\mathrm{d}t=\frac{\alpha}{2T}\tag{44}
\]</span> 所以，有： <span class="math display">\[
\lim_{T \to \infty}\frac{1}{2T}\int_{-T}^{T}f(t)\mathrm{d}t=0\tag{45}
\]</span> 对于第二个极限，先直接给出结论：</p>
<p>  令<span class="math inline">\(\lambda=n\omega=\frac{\pi}{T}\)</span>，有： <span class="math display">\[
\lim_{T \to
\infty}\sum_{n=1}^{\infty}\frac{1}{T}\int_{-T}^{T}f(t)cos[n\omega(x-t)]\mathrm{d}t=\frac{1}{\pi}\int_{0}^{+\infty}[\int_{-\infty}^{+\infty}f(t)cos[\lambda(x-t)]\mathrm{d}t]\mathrm{d}\lambda\tag{46}
\]</span></p>
</blockquote>
<p>于是，得到非周期函数<span class="math inline">\(f(x)\)</span>的傅立叶积分表示： <span class="math display">\[
f(x)
=\frac{1}{\pi}\int_{0}^{+\infty}[\int_{-\infty}^{+\infty}f(t)cos[\lambda(x-t)]\mathrm{d}t]\mathrm{d}\lambda\tag{47}
\]</span> 或写为： <span class="math display">\[
f(x)=\int_{0}^{+\infty}[A(\lambda)cos(\lambda x)+B(\lambda)sin(\lambda
x)]\mathrm{d}\lambda\tag{48}
\]</span> 其中： <span class="math display">\[
A(\lambda)=\frac{1}{\pi}\int_{-\infty}^{+\infty}f(t)cos(\lambda
t)\mathrm{d}t\\
B(\lambda)=\frac{1}{\pi}\int_{-\infty}^{+\infty}f(t)sin(\lambda
t)\mathrm{d}t
\tag{49}
\]</span>
综合来看，周期函数和有限区间上的函数可以用傅立叶级数来表示；而无穷区间的非周期函数，用傅里叶积分表示，对应了频率的连续分布。</p>
<h1 id="傅里叶变换">傅里叶变换</h1>
<p>  傅里叶级数的本质是函数在某个函数空间中各个基底的投影和，在上文中我们通过引入希尔伯特空间，构造标准正交三角函数系进而推导出傅立叶级数与傅立叶积分。然而，这一切都是基于实数域推导，那么这种思路在复数域是否也成立呢，答案是显而易见的。下面，我们通过欧拉公式（公式证明见文末）来得到傅立叶积分的复数形式：</p>
<p><span class="math display">\[
e^{ix}=cos(x)+isin(x)\tag{50}
\]</span>   观察（47）式，由于： <span class="math display">\[
\int_{-\infty}^{+\infty}f(t)cos[\lambda(x-t)]\mathrm{d}t=\lim_{\alpha
\to
\infty}\int_{-\alpha}^{\alpha}f(t)cos[\lambda(x-t)]\mathrm{d}t\tag{51}
\]</span> 因为 <span class="math display">\[
\begin{aligned}
\int_{-\alpha}^{\alpha}f(t)e^{i\lambda(x-t)}\mathrm{d}t&amp;=\int_{-\alpha}^{\alpha}f(t)\{cos[\lambda(x-t)]+isin[\lambda(x-t)]\}\mathrm{d}t\\
&amp;=\int_{-\alpha}^{\alpha}f(t)cos[\lambda(x-t)]\mathrm{d}t+i*0（奇函数在对称区间的积分为零）
\end{aligned}\tag{52}
\]</span> 则非周期函数<span class="math inline">\(f(x)\)</span>的傅立叶积分（47）可改写为： <span class="math display">\[
\begin{aligned}
f(x)&amp;=\frac{1}{\pi}\int_{0}^{+\infty}[\int_{-\infty}^{+\infty}f(t)cos[\lambda(x-t)]\mathrm{d}t]\mathrm{d}\lambda\\
&amp;=\frac{1}{\pi}\int_{0}^{+\infty}[\int_{-\infty}^{+\infty}f(t)e^{i\lambda(x-t)}\mathrm{d}t]\mathrm{d}\lambda\\
&amp;=\frac{1}{\pi}\int_{0}^{+\infty}e^{i\lambda
x}\int_{-\infty}^{+\infty}f(t)e^{-i\lambda
t}\mathrm{d}t\mathrm{d}\lambda\\
&amp;=\frac{1}{2\pi}\int_{-\infty}^{+\infty}e^{i\lambda
x}\color{#F00}{\int_{-\infty}^{+\infty}f(t)e^{-i\lambda
t}\mathrm{d}t}\mathrm{d}\lambda\\
\end{aligned}\tag{53}
\]</span>
上式最后一个等式即为傅立叶积分的复数形式，而红色积分部分就是大名鼎鼎的<code>傅立叶变换</code>也叫<code>像函数</code>，是一个复数表示<code>振幅</code>和<code>相位</code>：
<span class="math display">\[
F(\lambda)=\color{#F00}{\int_{-\infty}^{+\infty}f(t)e^{-i\lambda
t}\mathrm{d}t}\tag{54}
\]</span> 而<span class="math inline">\(f(x)\)</span>也称为<code>傅立叶逆变换</code>也叫<code>本函数</code>：
<span class="math display">\[
f(x)=\frac{1}{2\pi}\int_{-\infty}^{+\infty}e^{i\lambda
x}\color{#F00}{F(\lambda)}\mathrm{d}\lambda\tag{55}
\]</span>   <code>傅里叶变换</code>一词既指变换操作本身（将函数<span class="math inline">\(f(x)\)</span>
进行傅里叶变换），又指该操作所生成的复数函数（<span class="math inline">\(F(\lambda)\)</span>是<span class="math inline">\(f(x)\)</span>的傅里叶变换）,需要注意的是，一般情况下傅立叶变换是可逆的。</p>
<h2 id="傅立叶变换的性质">傅立叶变换的性质</h2>
<p>  傅立叶级数使用不同频率的三角函数和来表示周期函数和有限区上的函数，而傅立叶积分则是对频率作无穷积分来表示无穷区间上的函数。本质上其实是从不同的角度刻画相同的函数，所以你经常可以听到这样的说法，傅立叶变换是一种线性积分变换，常用于信号<code>时域</code>到<code>频域</code>之间的变换，这里说的<code>时域</code>是从时间的角度描述函数或信号，而<code>频域</code>则是从频率的角度描述函数或信号。本质上傅立叶变换就像化学分析，像分析物质的基本成分一样，确定函数或信号的基本组成。</p>
<p>  接下来讨论一下傅立叶变换的一些基本性质，为了方便描述，约定<span class="math inline">\(\mathscr{F}\)</span>为傅立叶变换的作用算子，即<span class="math inline">\(\mathscr{F}[f]=F[\lambda]\)</span>为<span class="math inline">\(f(x)\)</span>的傅立叶变换，<span class="math inline">\(\mathscr{F}^{-1}[F]=f(x)\)</span>表示<span class="math inline">\(F(\lambda)\)</span>的傅立叶逆变换，并且函数<span class="math inline">\(f(x),g(x)\)</span>都存在傅立叶变换：</p>
<ul>
<li><p>线性性质</p>
<p>两函数之和的傅里叶变换等于各自的傅立叶变换之和： <span class="math display">\[
\mathscr{F}[\alpha f+ \beta
g]=\alpha\mathscr{F}[f]+\beta\mathscr{F}[g]（\alpha,\beta \in C）
\]</span></p></li>
<li><p>频移性质 <span class="math display">\[
\mathscr{F}[f(x)e^{i\lambda_{0}x}]=\mathscr{F}[f](\lambda-\lambda_0)=F(\lambda-\lambda_0)（\lambda_0
\in R）
\]</span></p></li>
<li><p>时移特性 <span class="math display">\[
\mathscr{F}^{-1}[f(x)e^{i\lambda x_0}]=\mathscr{F}[{f}](x+x_0)
\]</span></p></li>
<li><p>帕塞瓦尔定理</p>
<p>  若<span class="math inline">\(f(x)\)</span>平方可积，则有： <span class="math display">\[
\int_{-\infty}^{+\infty}f^2(x)\mathscr{d}x=\frac{1}{2\pi}\int_{-\infty}^{+\infty}|F(\lambda)|^2\mathscr{d}\lambda
\]</span></p></li>
<li><p>卷积的傅里叶变换</p>
<p>  若<span class="math inline">\(f(x),g(x)，x \in
R\)</span>且在定义域内绝对可积，定义卷积函数： <span class="math display">\[
f*g = \int_{-\infty}^{+\infty}f(x-\xi)g(\xi)\mathscr{d}\xi
\]</span></p>
<p>则有： <span class="math display">\[
\begin{aligned}
&amp;\mathscr{F}[f*g]=\mathscr{F}[f]\cdot\mathscr{F}[g] \\
&amp;\mathscr{F}^{-1}[F(\lambda)*G(\lambda)] =
2\pi\mathscr{F}^{-1}[F(\lambda)]\cdot\mathscr{F}^{-1}[G(\lambda)]
\end{aligned}
\]</span>
  傅里叶变换在时域和频域之间搭起来一座桥梁，一些在时域很难解决甚至无法解决的问题，在频域下却可以轻松得到解决，在信号、图像处理还有偏微分方程等领域都有着广泛的应用。</p></li>
</ul>
<h2 id="离散傅里叶变换">离散傅里叶变换</h2>
<p>  <strong>离散傅里叶变换</strong>（Discrete Fourier
Transform，缩写为DFT），是傅里叶变换在时域和频域上都呈离散的形式，将信号的时域采样变换为其离散时间傅里叶变换的频域采样。</p>
<p>对于序列<span class="math inline">\({x[n]|,n=0,1,\dots,N-1}\)</span>
其离散傅里叶变换（DFT）如下：<br>
<span class="math display">\[
  \hat{x}[k]=\sum_{n=0}^{N-1}e^{-i\frac{2nk\pi}{N}}x[n]\quad
k=0,1,\dots,N-1.
\]</span> 离散傅里叶变换的逆变换（IDFT）如下： <span class="math display">\[
  x[n]=\frac{1}{N}\sum_{k=0}^{N-1}e^{i\frac{2nk\pi}{N}}\hat{x}[k] \quad
n=0,1,\dots,N-1
\]</span> 离散傅里叶变换的应用：</p>
<blockquote>
<ul>
<li>数据压缩</li>
</ul>
</blockquote>
<blockquote>
<p>  由于人类感官的分辨能力存在极限，因此很多有损压缩算法利用这一点<strong>将语音、音频、图像、视频等信号的高频部分除去</strong>。高频信号对应于信号的细节，滤除高频信号可以在人类感官可以接受的范围内获得很高的压缩
比。这一去除高频分量的处理就是通过离散傅里叶变换完成的。将时域或空域的信号转换到频域，仅储存或传输较低频率上的系数，在解压缩端采用逆变换即可重建信号。</p>
</blockquote>
<blockquote>
<ul>
<li>长整数与多项式乘法</li>
</ul>
</blockquote>
<blockquote>
<p>  目前长整数或多项式乘法最快速的算法是基于离散傅里叶变换的。由于整数（或多项式）乘法是逐位（或逐项）乘累加的形式，因此整数（或多项式）乘积的数字（或系数）可以用乘数数字（或乘式系数）的卷积表示。利用&gt;卷积定理，只要将数字（或系数）序列通过离散傅里叶变换变到频域，就可以将逐个乘累加的卷积变为对位的乘法，从而减少计算量，再以一次逆变换便可以得到乘法结果。需要注意整数乘法还有进位的问题。</p>
</blockquote>
<blockquote>
<ul>
<li>求解偏微分方程</li>
</ul>
</blockquote>
<blockquote>
<p>  离散傅里叶变换及其多维形式在偏微分方程的求解中也有应用。此时DFT被看作傅里叶级数的近似。傅里叶级数将函数在复指数<span class="math inline">\(e^{i\lambda
x}\)</span>上展开，这正是微分算子的特征方程： <span class="math display">\[
\frac{d}{dx}e^{i\lambda x}=i\lambda e^{i\lambda x}
\]</span>
  因此，通过傅里叶级数的形式，线性常微分方程被转换为代数方程，而后者是很容易求解的。此时得到的结果是偏微分方程解的级数表示，只要通过DFT逆变换即可得到其一般表示，这种方法被称作谱方法或级数解法。</p>
</blockquote>
<h1 id="快速傅里叶变换">快速傅里叶变换</h1>
<p>  离散傅里叶变换十分强大，但是计算复杂度较高，对于一个大小为<span class="math inline">\(n\)</span>的序列，其离散傅里叶级数的复杂度为<span class="math inline">\(O(n^2)\)</span>，对于一些需要实时计算的场景，不太能满足需求。因此，快速傅里叶变换（FFT）应运而生，快速傅里叶变换是快速计算序列的离散傅里叶变换]叶变换)（DFT）或其逆变换的方法。傅里叶分析将信号从原始域（通常是时间或空间）转换到频域的表示或者逆过来转换。FFT会通过把DFT矩阵分解为稀疏因子之积来快速计算此类变换，
因此，它能够将计算DFT的复杂度从<span class="math inline">\(O(n^2)\)</span>降低到<span class="math inline">\(n\log_2 n\)</span>。</p>
<p>  FFT的本质就是通过不断的把长序列的DFT分解为几个短序列的DFT，并利用单位根的周期性和对称性来减少计算量。FFT算法有很多种，不过大致可以分为两类：</p>
<blockquote>
<p><strong>按抽取方法可分为</strong>：</p>
<ul>
<li>时域抽取法（DIT）</li>
<li>频域抽取大（DIF）</li>
</ul>
<p><strong>按<code>基数</code>可分为</strong>：</p>
<ul>
<li>基2-FFT算法</li>
<li>基4-FFT算法</li>
<li>混合基FFT算法</li>
<li>分裂基FFT算法</li>
</ul>
</blockquote>
<h2 id="cooley-tukey算法">Cooley-Tukey算法</h2>
<p>  Cooley-Tukey算法是最常见的FFT算法。这一方法以分治法为策略递归地将长度为<span class="math inline">\(N=N_{1}N_{2}\)</span>的离散傅里叶变换分解为长度为<span class="math inline">\(N_{1}\)</span>的<span class="math inline">\(N_{2}\)</span>个较短序列的离散傅里叶变换，以及与<span class="math inline">\(\mathrm {O} (N)\)</span>个转因子的复数乘法。</p>
<p>  Cooley-Tukey算法最有名的应用，是将序列长为<span class="math inline">\(N\)</span> 的DFT分割为两个长为<span class="math inline">\(\frac{N}{2}\)</span>
的子序列的DFT，因此这一应用只适用于序列长度为2的幂的DFT计算，即基2-FFT。实际上，如同高斯和Cooley与Tukey都指出的那样，<strong>Cooley-Tukey算法也可以用于序列长度<em>N</em>
为任意因数分解形式的DFT，即混合基FFT，而且还可以应用于其他诸如分裂基FFT等变种</strong>。尽管Cooley-Tukey算法的基本思路是采用递归的方法进行计算，大多数传统的算法实现都将显式的递归算法改写为非递归的形式。另外，因为Cooley-Tukey算法是将DFT分解为较小长度的多个DFT，因此它可以同任一种其他的DFT算法联合使用。</p>
<h3 id="基2时间抽取法">基2时间抽取法</h3>
<p>  基2时间抽取算法是Cooley-Tukey算法的一种分支，当序列<span class="math inline">\(x(n)\)</span>的点数为<span class="math inline">\(N=2^{M}\quad M \in
\N\)</span>（若不满足，可补零），此时的Cooley-Tukey算法称之为基2时间抽取法。由于序列点数为2的整数幂，则可以将序列按序号<span class="math inline">\(n\)</span>的奇偶性分为两组：</p>
<ul>
<li><p>偶序列 <span class="math display">\[
x_1=x_{(2r)} \quad r = 0,1,\dots,\frac{N}{2}-1
\]</span></p></li>
<li><p>奇序列 <span class="math display">\[
x_2=x_{(2r+1)} \quad r = 0,1,\dots,\frac{N}{2}-1
\]</span>
即一组由偶数序号组成，另外一组由奇数序号组成（注意数据长度为<span class="math inline">\(\frac{N}{2}\)</span>）</p></li>
</ul>
<h2 id="互质因子算法">互质因子算法</h2>
<p><a href="https://www.wikiwand.com/zh/%E4%BA%92%E8%B3%AA%E5%9B%A0%E5%AD%90%E7%AE%97%E6%B3%95">互质因子算法</a></p>
<h2 id="winograd算法">Winograd算法</h2>
<p><a href="https://www.wikiwand.com/zh/%E5%A8%81%E8%AB%BE%E6%A0%BC%E6%8B%89%E5%BE%B7%E5%BF%AB%E9%80%9F%E5%82%85%E7%AB%8B%E8%91%89%E8%AE%8A%E6%8F%9B%E6%BC%94%E7%AE%97%E6%B3%95">Winograd算法</a></p>
<ul>
<li><p>拉普拉斯变换</p>
<p><a href="https://zhuanlan.zhihu.com/p/40783304">拉普拉斯变换</a></p>
<p><strong>傅里叶变换是将函数分解到频率不同、幅值恒为1的单位圆上；拉普拉斯变换是将函数分解到频率幅值都在变化的圆上。因为拉普拉斯变换的基有两个变量，因此更灵活，适用范围更广。</strong></p></li>
</ul>
<blockquote>
<p>关于快速傅里叶变换只是做了简单的介绍和梳理,详细内容等以后有时间再更新。</p>
</blockquote>
<h1 id="概念解析">概念解析</h1>
<ul>
<li><code>酉空间</code></li>
</ul>
<p>设<span class="math inline">\(V\)</span>为一个复数域<span class="math inline">\(F\)</span>上的线形空间，若在<span class="math inline">\(V\)</span>中定义了两个变量<span class="math inline">\(\alpha,\beta\)</span>的内积（数量积），记作<span class="math inline">\((\alpha,\beta)\)</span>，且满足：</p>
<p><span class="math inline">\((i)\)</span> <span class="math inline">\((\alpha,\beta)=\overline{(\beta,\alpha)}\)</span>，其中<span class="math inline">\(\overline{(\beta,\alpha)}\)</span>是<span class="math inline">\((\alpha,\beta)\)</span>的共轭</p>
<p><span class="math inline">\((ii)\)</span> <span class="math inline">\((\alpha,\alpha) \geq0\)</span>，当且仅当<span class="math inline">\(\alpha=0\)</span>时等号成立</p>
<p><span class="math inline">\((iii)\)</span> <span class="math inline">\((a_1\alpha_1+a_2\alpha_2,\beta)=a_1(\alpha_1,\beta)+a_2(\alpha_2,\beta)\)</span>,对任意<span class="math inline">\(\alpha_1,\alpha_2,\beta\in V,a_1,a_2\in
F\)</span></p>
<p>则称<span class="math inline">\(V\)</span>为酉空间(<span class="math inline">\(U\)</span>空间)，又称为内积空间，当<span class="math inline">\(F\)</span>为实数域时，此时的内积是可交换的，有限维的实酉空间也就是欧几里德空间。直观来说，酉空间就是将欧几里德空间的内积运算从实数域拓展到复数域。</p>
<ul>
<li><p><code>完备性</code></p>
<p>一个向量空间具有完备性指空间中的任何<a href="https://www.wikiwand.com/zh/柯西序列">柯西序列</a>都收敛在该空间之内。。</p></li>
<li><p><code>柯西列</code></p>
<p>  柯西列就是空间中元素构成的一个序列，并且这个序列在无穷远处两个元素之间的距离趋于零。准确的说，如果空间中有一个序列
<span class="math inline">\(\{x_n\}\)</span> ,当<span class="math inline">\(n,m \to \infty\)</span>的时候，<span class="math inline">\(||x_n-x_m|| \to 0\)</span>
（即二者的距离趋零），则 <span class="math inline">\(\{x_n\}\)</span>就是一个柯西列，也就是说完备性保证了取序列极限不会跑到空间外面去。一个<strong>不完备</strong>的例子就是有理数的集合，例如这个集合可以用柯西列的极限去逼近<span class="math inline">\(\sqrt{2}\)</span>
，而这个极限并不在有理数这个集合中，所以有理数集合是不完备的，而实数集合是完备的。</p></li>
<li><p>三角恒等式</p>
<p><a href="https://www.wikiwand.com/zh/%E4%B8%89%E8%A7%92%E6%81%92%E7%AD%89%E5%BC%8F#/%E4%BA%8C%E5%80%8D%E8%A7%92%E3%80%81%E4%B8%89%E5%80%8D%E8%A7%92%E5%92%8C%E5%8D%8A%E8%A7%92%E5%85%AC%E5%BC%8F">维基百科：三角恒等式</a></p></li>
<li><p>内积空间</p>
<p>  <strong>内积空间</strong>是<a href="https://www.wikiwand.com/zh-hans/线性代数">线性代数</a>里的基本概念，是增添了一个额外的结构的<a href="https://www.wikiwand.com/zh-hans/向量空间">向量空间</a>。这个额外的结构叫做<strong><a href="https://www.wikiwand.com/zh-hans/内积">内积</a></strong>或<a href="https://www.wikiwand.com/zh-hans/标量积">标量积</a>。内积将一对<a href="https://www.wikiwand.com/zh-hans/向量">向量</a>与一个标量连接起来，允许我们严格地谈论<a href="https://www.wikiwand.com/zh-hans/向量">向量</a>的“<a href="https://www.wikiwand.com/zh-hans/角">夹角</a>”和“<a href="https://www.wikiwand.com/zh-hans/长度">长度</a>”，并进一步谈论向量的<a href="https://www.wikiwand.com/zh-hans/正交">正交性</a>。内积空间由<a href="https://www.wikiwand.com/zh-hans/欧几里得空间">欧几里得空间</a>抽象而来（内积是点积的抽象），这是<a href="https://www.wikiwand.com/zh-hans/泛函分析">泛函分析</a>讨论的课题。</p></li>
<li><p>欧拉公式的证明</p>
<p>  欧拉公式（50）的证明方式有两种，第一种是构造函数：</p></li>
</ul>
<p><span class="math display">\[
  f(x)=\frac{e^{ix}}{cos(x)+isin(x)}
\]</span></p>
<p>利用拉格朗日中值定理证明<span class="math inline">\(f(x)=1\)</span>即可；第二种则是使用麦克劳林级数分别展开得到：
<span class="math display">\[
  \begin{aligned}
  e^{ix}&amp;=\sum_{i=0}^{\infty}\frac{(ix)^n}{n!}=1+ix-\frac{x^2}{2!}-i\frac{x^3}{3!}+\dots+i^n\frac{x^n}{n!}+\dots（\forall
x \in R）\\
  cos(x)&amp;=\sum_{i=0}^{\infty}\frac{(-1)^n}{n!}x^{2n}=1-\frac{x^2}{2!}+\frac{x^4}{4!}+\dots+\frac{(-1)^n}{(2n)!}x^{2n}+\dots（\forall
x \in R）\\
  isin(x)&amp;=i\sum_{i=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}=ix-i\frac{x^3}{3!}+i\frac{x^5}{5!}+\dots+i\frac{(-1)^n}{(2n+1)!}x^{2n+1}+\dots（\forall
x \in R）
  \end{aligned}
\]</span>
后两者的麦克劳林级数展开相加刚好等于前者的麦克劳林级数展开。在此只补充拉格朗日中值定理，具体证明过程较简单，不做详细展开。</p>
<blockquote>
<p>拉格朗日中值定理:</p>
<p>  如果函数<span class="math inline">\(f(x)\)</span>，在闭区间<span class="math inline">\([a,b]\)</span>上连续，在开区间<span class="math inline">\((a,b)\)</span>内可微。则少存在一点<span class="math inline">\(\xi \in (a,b)\)</span>，使下面的等式成立: <span class="math display">\[
f(b)-f(a)=f^\prime(\xi)(b-a)
\]</span> 推论：</p>
<p>  若函数<span class="math inline">\(f(x)\)</span>的导数恒为零，则<span class="math inline">\(f(x)\)</span>为常值函数，即<span class="math inline">\(f(x)=C,C \in R\)</span>。</p>
</blockquote>
]]></content>
      <tags>
        <tag>傅立叶</tag>
        <tag>希尔伯特空间</tag>
        <tag>正交函数系</tag>
      </tags>
  </entry>
  <entry>
    <title>初探Transformer架构</title>
    <url>/posts/a65e2a56/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>卡尔曼滤波</title>
    <url>/posts/b654ab75/</url>
    <content><![CDATA[<p>  <strong>卡尔曼滤波</strong>（Kalman filter）是一种高效率的<a href="https://www.wikiwand.com/zh-hans/递归滤波器">递归滤波器</a>（<a href="https://www.wikiwand.com/zh-hans/自迴歸模型">自回归</a>滤波器），它能够从一系列的不完全及包含<a href="https://www.wikiwand.com/zh-hans/雜訊_(通訊學)">杂讯</a>的<a href="https://www.wikiwand.com/zh-hans/测量">测量</a>中，估计<a href="https://www.wikiwand.com/zh-hans/动态系统">动态系统</a>的状态。卡尔曼滤波会根据各测量量在不同时间下的值，考虑各时间下的<a href="https://www.wikiwand.com/zh-hans/联合分布">联合分布</a>，再产生对未知变数的估计，因此会比只以单一测量量为基础的估计方式要准。卡尔曼滤波得名自主要贡献者之一的<a href="https://www.wikiwand.com/zh-hans/鲁道夫·卡尔曼">鲁道夫·卡尔曼</a>，最早用于解决阿波罗计划的轨道预测问题。
<span id="more"></span>
  上面的定义摘自维基百科，是对卡尔曼滤波的专业阐述，为了便于理解通过下面两个例子来对卡尔曼滤波有个大致的了解。</p>
<p>  航天器的发动机能够在足够高的温度下燃烧燃料，为航天器提供足够的动力，航天器发动机燃烧室在燃烧时温度可以达到数千摄氏度，过高的温度可能会损坏发动机的机械部件，导致火箭发射失败，因此需要密切关注火箭燃烧室的内部温度，显然在燃烧室内部放置温度传感器会直接被融化。此时，无法直接测量燃烧室的内部温度，基于这种情况，可以在燃烧室外放置一个温度传感器测量燃烧室的外部温度，使用卡尔曼滤波器利用外部温度来估算燃烧室的内部温度。</p>
<p>  这是卡尔曼滤波器一种使用方式：</p>
<blockquote>
<p>  当系统的状态无法通过直接测量得到但是可以间接测量时，可以使用卡尔曼滤波通过间接测量值来估算系统的状态。
总所周知，汽车的导航系统使用<code>车载传感器（Onboard sensors）</code>得到汽车的当前位置并导航到目的地。常用的车载传感器有：<code>惯性测量单元（Inertial measurement unit,IMU）</code>使用加速度计和陀螺仪来测量汽车的加速度和角速度；<code>里程表(Odometer)</code>测量汽车的相对行驶距离；<code>GPS接收器(GPS receiver)</code>接收来自GPS卫星的信号，来确定汽车在地球表面的位置。</p>
</blockquote>
<blockquote>
<p>  IMU中的加速度计提供了汽车当前的加速度大小及方向，但是想要获得汽车的位置，需要对加速度进行两次积分（<span class="math inline">\(s =\iint
a(t)dt\)</span>）得到汽车的位置，数值积分算法在计算位置时会存在微小的误差并且会随着时间的累积会不断，最终产生积分漂移，完全偏离汽车的正确位置；里程表容易受到轮胎压力和道路状况的影响；而GPS位置跟新速度慢，而且会存在一定噪声，最大问题还是在车辆通过隧道或车库时，信号很差，甚至无法接收到信号。三种车载传感器各自有各自的局限和优势，只用单独一种传感器进行定位效果都不尽如人意，此时可以使用卡尔曼滤波融合三种传感器得到汽车位置的最优估计值。</p>
</blockquote>
<p>  这是卡尔曼滤波的另一种使用方式：</p>
<blockquote>
<p>组合各种可能受到噪声影响的传感器测量值，得到一个最优的估计值。</p>
</blockquote>
<p>  卡尔曼滤波主要应用于高精度传感系统中，在时下大热的机器人、无人机、自动导航都有着应用，由于其递归的特性（即只要获知上一时刻状态的估计值以及当前状态的观测值就可以计算出当前状态的估计值），因此不需要记录观测或者估计的历史信息。与大多数滤波器不同之处，卡尔曼滤波器是一种纯粹的<a href="https://www.wikiwand.com/zh-hans/時域">时域</a>滤波器，它不需要像<a href="https://www.wikiwand.com/zh-hans/低通滤波器">低通滤波器</a>等<a href="https://www.wikiwand.com/zh-hans/频域">频域</a>滤波器那样，需要在频域设计再转换到时域实现。</p>
<p>  其本质思想是采用信号与噪声的状态空间模型，利用前一时刻地估计值和现时刻的观测值来更新对状态变量的估计，求出现时刻的估计值，它适合于实时处理和计算机运算。下面我们一步步来解开卡尔曼滤波的神秘面纱。</p>
<hr>
<h3 id="隐马尔可夫">隐马尔可夫</h3>
<h4 id="随机过程">随机过程</h4>
<p>  随机过程被认为是概率论的“动力学”部分，其研究对象是随时间演变的随机现象。对于这种现象，已不能用随机变量或多维随机变量来合理表达，而需要一族（无限多个）随机变量来描述。高等教育出版社的《概率论和数理统计》第四版是这样定义随机过程：</p>
<blockquote>
<p>  设<span class="math inline">\(T\)</span>是一无限实数集，我们把依赖于参数<span class="math inline">\(t\in
T\)</span>的一族随机变量称为<code>随机过程</code>，记为<span class="math inline">\(\{X(t),t\in T\}\)</span>,其中对<span class="math inline">\(\forall t \in T,X(t)\)</span>是一随机变量，<span class="math inline">\(T\)</span>叫做<code>参数集</code>。通常把<span class="math inline">\(t\)</span>看作时间，称<span class="math inline">\(X(t)\)</span>为时刻<span class="math inline">\(t\)</span>时过程的状态，而<span class="math inline">\(X(t_1)=x,x \in R\)</span>定义为<span class="math inline">\(t=t_1\)</span>时过程处于状态<span class="math inline">\(x\)</span>，对于<span class="math inline">\(\forall t\in
T,X(t)\)</span>的所有可能取一切值的全体称为随机过程的<code>状态空间</code>，<code>泊松过程</code>和<code>维纳过程</code>都是典型的随机过程，篇幅有限这里不做进一步展开，有兴趣的读者可以自行Google。</p>
</blockquote>
<h4 id="马尔可夫过程">马尔可夫过程</h4>
<p>  一个随机过程在时刻<span class="math inline">\(t_0\)</span>所处的状态为已知的条件下，随机过程在时刻<span class="math inline">\(t（t&gt;t_0)\)</span>所处的状态与其在时刻<span class="math inline">\(t_0\)</span>之前所处的状态无关。简而言之，就是“将来”仅依赖于”现在”与“过去”无关。我们称这种特性为<code>马尔可夫性</code>或无后效性。而这种具有马尔可夫性质的随机过程称之为<code>马尔可夫过程</code>，可以推出，泊松过程是时间连续状态离散的马尔可夫过程，而维纳过程则是时间状态都连续的马尔可夫过程。对于时间和状态都是离散的马尔可夫过程就是构成卡尔曼滤波的重要基石<code>马尔可夫链</code>：</p>
<p>  对于随机过程<span class="math inline">\({X_n,n=1,2,\cdots}\)</span>,若其条件概率分布满足:
<span class="math display">\[
P\{X_{n+1}=x_{n+1}|X_n=x_n,\cdots,X_1=x_1\}=P\{X_{n+1}=x_{n+1}|X_n=x_n\}
\]</span>，则称此随机过程为马尔可夫链。</p>
<h4 id="状态转移矩阵">状态转移矩阵</h4>
<p>  在马尔可夫链中，从一个状态转移到另一个状态的概率称为状态转移概率，如果系统的可能状态是有限的，例如有<span class="math inline">\(K\)</span>个状态，则状态转移概率构成一个<span class="math inline">\(K\times K\)</span>的状态转移矩阵： <span class="math display">\[P=\left[ \begin{matrix}   p_{11} &amp; p_{12}
&amp; \cdots &amp; p_{1K} \\ p_{21} &amp; p_{22} &amp; \cdots &amp;
p_{2K}\\ \cdots &amp; \cdots &amp; \cdots &amp;\cdots \\ p_{K1} &amp;
p_{K2} &amp; \cdots &amp; p_{KK}\end{matrix}  \right]\]</span>
其中矩阵的每一行的和为1，该矩阵是一个随机矩阵，任何一个随机矩阵都可以作为状态转移矩阵
。</p>
<h4 id="隐马尔可夫模型">隐马尔可夫模型</h4>
<p>  在马尔可夫模型中，系统的状态是直接可见的，这样状态的转移概率就可以构成该系统的全部参数。但是，在实际生活中更多的情况是：系统状态并不是直接可见，我们往往只能观测到受状态影响的某些变量。显然对这些可观测到的变量使用马尔可夫模型对系统进行状态分析是不严谨的。为此，对于这种含有隐含未知参数的马尔可夫过程，数学家通过随机过程可观察的参数确定该过程的隐含参数，然后利用这些参数来作进一步分析，这也是大名鼎鼎的<code>隐马尔可夫模型（Hidden Markov model，HMM）</code>的本质，至于隐马尔可夫模型的更多详细内容，如果进行展开的话，需要花费大量篇幅，在此先不做展开。隐马尔可夫模型在语音识别和模式识别领域都有着应用，而卡尔曼滤波也是构建在隐马尔可夫模型之上的。</p>
<h3 id="线性卡尔曼滤波">线性卡尔曼滤波</h3>
<p>  <code>卡尔曼滤波是一个递归滤波器，其算法本质是通过动态系统的有限个观测值，估计动态系统的隐藏状态。</code>接下来，我们从动态系统的状态空间模型开始，一步步推导卡尔曼滤波算法。</p>
<h4 id="状态空间模型">状态空间模型</h4>
<p>  动态系统都具有一个基本特征：系统的状态，那么什么是系统的状态呢，其定义如下：</p>
<blockquote>
<p>  一个随机动态系统的状态被定义为最少量的信息，这些信息包含过去作用于该系统的输入的影响，并足以完全描述系统将来的行为。（该定义截取自机械工业出版社译制的《神经网络与机器学习》第三版
第十四章 动态系统状态估计的贝叶斯滤波）</p>
</blockquote>
<p>  通常我们使用状态空间模型来描述动态系统状态对外部世界的影响，一般而言，状态空间模型分为两个部分：</p>
<blockquote>
<ul>
<li><p>系统模型</p>
<p>  系统模型使用时域函数来描述动态系统状态的演变，其数学表示为一阶马尔可夫链：<span class="math inline">\(x_{n+1}=\zeta_{n}(x_n,\omega_n)\)</span>，其中<span class="math inline">\(n\)</span>表示离散时间，向量<span class="math inline">\(x_n\)</span>表示动态系统当前的状态，向量<span class="math inline">\(x_{n+1}\)</span>表示下一状态的值，向量<span class="math inline">\(\omega_n\)</span>表示过程噪声，<span class="math inline">\(\zeta\)</span>为<span class="math inline">\(x_n,\omega_n\)</span>的向量函数，会随时间改变。</p></li>
<li><p>测量模型</p>
<p>  测量模型描述了动态系统状态对外部世界的影响，公式如下：<span class="math inline">\(y_n = \xi(x_n,v_n)\)</span>，其中向量<span class="math inline">\(y_n\)</span>表示外部世界对动态系统的一组观测值，向量<span class="math inline">\(v_n\)</span>是外部世界噪声的测量值，<span class="math inline">\(\xi\)</span>是<span class="math inline">\(x_n,v_n\)</span>的向量函数，会随时间改变。</p></li>
</ul>
</blockquote>
<p>  对于状态空间模型，有着如下假设：</p>
<blockquote>
<ul>
<li>动态系统的任意时刻<span class="math inline">\(k\)</span>,其过程噪声<span class="math inline">\(\omega_k\)</span>与初始状态<span class="math inline">\(x_0\)</span>无关；</li>
<li>动态系统的过程噪声<span class="math inline">\(\omega_n\)</span>于测量噪声<span class="math inline">\(v_n\)</span>是统计独立，也就是说对<span class="math inline">\(\forall i,j\)</span>都有<span class="math inline">\(E[\omega_iv_j^T]=0\)</span>成立；</li>
</ul>
</blockquote>
<p>  一般而言，跟状态与状态之间的是否为线性关系及过程噪声、测量噪声二者是否服从高斯分布将状态空间模型分为四大类：</p>
<blockquote>
<ul>
<li>线性高斯模型</li>
<li>线性非高斯模型</li>
<li>非线性高斯模型</li>
<li>非线性非高斯模型</li>
</ul>
</blockquote>
<p>  显然不管是非线性还是非高斯或二者兼之的状态空间模型，其处理难度是远高于线性高斯模型的，我们先来处理最简单的状态空间模型——线性高斯模型。</p>
<h4 id="线性卡尔曼滤波的理论推导">线性卡尔曼滤波的理论推导</h4>
<p>对于线性高斯模型，其状态空间模型可设为如下形式：</p>
<p><span class="math display">\[
\begin{cases}
x_{n}=A_{n}x_{n-1}+\omega_{n} \\
y_n = H_nx_n+v_n
\end{cases}
\]</span>   其中<span class="math inline">\(\omega_n\sim N(0,Q),v_n\sim
N(0,R)\)</span>，<span class="math inline">\(A_{n+1}\)</span>是动态系统从状态<span class="math inline">\(x_n\)</span>到<span class="math inline">\(x_{n+1}\)</span>的状态转移矩阵，<span class="math inline">\(H_n\)</span>是测量矩阵，表示系统状态<span class="math inline">\(x_n\)</span>对<span class="math inline">\(y_n\)</span>的增益，将系统状态映射到外部世界。</p>
<p>  考虑到动态系统会受到系统中已知的控制器的控制信息的影响，需要在系统模型中加入这部分信息，修正后的状态空间模型如下：</p>
<p><span class="math display">\[
\begin{cases}
x_{n}=A_{n}x_{n-1}+B_{n}\mu_{n}+\omega_{n} \\ y_n = H_nx_n+v_n
\end{cases}
\]</span> 其中<span class="math inline">\(\mu_n\)</span>是系统的控制器向量，<span class="math inline">\(B_n\)</span>是系统的控制向量。</p>
<p>  为方便进行推导，定义<span class="math inline">\(\hat{x}^{-}_k \in
R^n\)</span>（<span class="math inline">\(^-\)</span>代表先验,^代表估计）为在已知第<span class="math inline">\(k\)</span>步以前状态情况下第<span class="math inline">\(k\)</span>步的先验状态估计。定义<span class="math inline">\(\hat{x}_k\in R^n\)</span>为已知观测变量<span class="math inline">\(y_k\)</span>时，第<span class="math inline">\(k\)</span>步的后验估计状态，由此定义先验估计误差和后验估计误差：</p>
<p><span class="math display">\[
\begin{cases}
  e_k^-\equiv{x_k-\hat{x}_k^-} \\ e_k\equiv{x_k-\hat{x}_k}
\end{cases}
\]</span> 先验估计误差的协方差为：</p>
<p><span class="math display">\[
P_k^-=E[e_k^-{e_k^-}^T]
\]</span> 后验误差估计的协方差为： <span class="math display">\[
P_k=E[e_ke_k^T]
\]</span>   显然<span class="math inline">\(P_k^-\)</span>是真实值和预测值之间的协方差，<span class="math inline">\(P_k\)</span>是真实值和最优估计值之间的协方差。卡尔曼滤波的核心就是如何根据<span class="math inline">\(k-1\)</span>时刻的最优状态估计<span class="math inline">\(\hat{x}_{k-1}\)</span>和第<span class="math inline">\(k\)</span>时刻的观测值<span class="math inline">\(y_k\)</span>得到<span class="math inline">\(k\)</span>时刻的最优状态估计值<span class="math inline">\(\hat{x}_k\)</span>,显然根据定义<span class="math inline">\(P_k\)</span>越小，估计值越接近于真实值，此时，只需求解当前条件下使得<span class="math inline">\(P_k\)</span>最小的状态估计值即是当前时刻状态的最优估计值。利用上文修正后的状态空间模型的系统模型得到<span class="math inline">\(k\)</span>时刻状态的预测值<span class="math inline">\(\hat{x}_k^-=A\hat{x}_{k-1}+B\mu_k\)</span>，为了得到<span class="math inline">\(k\)</span>时刻的最小协方差<span class="math inline">\(P_k\)</span>，卡尔曼滤波定义参数卡尔曼增益<span class="math inline">\(K=\frac{\hat{x}_k-\hat{x}_k^-}{y_k-H\hat{x}_k^-}\)</span>，其中，观测向量及其预测之差<span class="math inline">\(y_k-H\hat{x}_k^-\)</span>被称为测量过程的新息或残余。新息反应了预测值和实际值之间的不一致程度，为零时表明二者完全吻合，推导过程如下。</p>
<hr>
<p>由卡尔曼增益的定义式变形得到:</p>
<p><span class="math display">\[\hat{x}_k=\hat{x}_k^-+K(y_k-H\hat{x}_k^-)\]</span></p>
<p>将状态空间模型的观测模型代入得到:</p>
<p><span class="math display">\[\hat{x}_k=\hat{x}_k^-+K(Hx_k
+v_k-H\hat{x}_k^-)\]</span></p>
<p>进一步整理变换得到:</p>
<p><span class="math display">\[\hat{x}_k-x_k=\hat{x}_k^—x_k+KH(x_k-\hat{x}_k^-)+Kv_k\]</span></p>
<p>结合先验估计误差和后验估计误差的定义可知:</p>
<p><span class="math display">\[e_k=(I-KH)e_k^-+Kv_k\]</span></p>
<p>代入后验误差协方差的定义计算得到:</p>
<p><span class="math display">\[P_k=E[e_ke_k^T]=
E[[(I-KH)e_k^—Kv_k][(I-KH)e_k^—Kv_k]^T]\]</span></p>
<p>展开可知:</p>
<p><span class="math display">\[P_k=P^-_k-KHP^-_k-P^-_kH^TK^T+K(HP^-_kH^T+R)K^T=P(K)\]</span></p>
<p>要求<span class="math inline">\(P_k\)</span>的最小值，结合上式对卡尔曼增益<span class="math inline">\(K\)</span>求偏导，得到：</p>
<p><span class="math display">\[\frac{\partial{P_k}}{\partial{K}}=-2P^-_kH^T+2KHP_k^-H^T+2KR\]</span></p>
<blockquote>
<p>  需要注意的是，因为涉及到矩阵导数，与常规导数求导略有不同，有兴趣的读者，可以结合下面的矩阵求导规则进行求导：</p>
<p>若<span class="math inline">\(Y=AX\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=A^T\)</span>；</p>
<p>若<span class="math inline">\(Y=XA\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=A\)</span>；</p>
<p>若<span class="math inline">\(Y=A^TXB\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=AB^T\)</span>；</p>
<p>若<span class="math inline">\(Y=A^TX^TB\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=BA^T\)</span>；</p>
<p>若<span class="math inline">\(Y=X^TX\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=\)</span>X；</p>
<p>若<span class="math inline">\(Y=AX^T\)</span>,则<span class="math inline">\(\frac{d{Y}}{d{X}}=A\)</span>；</p>
<p>若<span class="math inline">\(Y=u(X)^Tv(X)\)</span>,则<span class="math inline">\(\frac{d{uv}}{d{X}}=\frac{du^T}{dX}v+\frac{dv^T}{X}u\)</span>；</p>
</blockquote>
<p>令<span class="math inline">\(\frac{\partial{P_k}}{\partial{K}}=0\)</span>，求解得到:</p>
<p><span class="math display">\[K=\frac{P^-_kH^T}{HP^-_KH^T+R}\]</span></p>
<blockquote>
<p>直观来看，一方面：</p>
<p><span class="math display">\[\lim\limits_{R\to0}K=\lim\limits_{R\to0}\frac{P_k^-H^T}{HP_k^-H^T+R}=H^{-1}\]</span></p>
<p>即，随着观测噪声协方差 <span class="math inline">\(R\)</span>的减小，卡尔曼增益逐渐增大，当<span class="math inline">\(R=0\)</span>时，取得最大值<span class="math inline">\(H^{-1}\)</span>;</p>
<p>另一方面：</p>
<p><span class="math display">\[\lim\limits_{P_k^-\to0}K=0\]</span></p>
<p>即，随着先验估计协方差<span class="math inline">\(P_k^-\)</span>的减小，卡尔曼增益随之减小，当<span class="math inline">\(P_k^-=0\)</span>时，取得最小值0；</p>
<p>结合卡尔曼增益的定义可知，<code>卡尔曼增益实际上表征了状态最优估计过程中模型预测误差与量测误差的比重，随着观测噪声协方差趋近于零，模型中预测误差的比重越来越大，此时模型更信任模型中观测值的信息；另一方面，随着先验估计误差协方差趋近于零，模型中预测误差的比重越来越小，此时模型更信任模型中预测值的信息。</code></p>
</blockquote>
<p>代入矩阵函数<span class="math inline">\(P(K)\)</span>得到：</p>
<p><span class="math display">\[P_k=(I-KH)P_k^-\]</span></p>
<p>至此，我们已经得到了第<span class="math inline">\(k\)</span>时刻最优状态估计值为：</p>
<p><span class="math display">\[\hat{x}_k
=\hat{x}_k^-+K(y_k-H\hat{x}_k^-)\]</span></p>
<p>  但是，到了这一步问题仍然没有得到解决，因为在计算<span class="math inline">\(k\)</span>时刻的卡尔曼增益时，仍有一个值未确定的：先验估计的协方差矩阵<span class="math inline">\(P_k^-\)</span>，在计算<span class="math inline">\(P_k^-\)</span>之前，需要先计算先验误差：</p>
<p><span class="math display">\[
e^-_k=x_k-\hat{x}_k^-=(Ax_{k-1}+B\mu_k+\omega_k)-(A\hat{x}_{k-1}+Bu_k)=Ae_{k-1}+\omega_k
\]</span> 因为</p>
<p><span class="math display">\[
P_k^-=E[e_k^-{e_k^-}^T]=E[(Ae_{k-1}+\omega_k)(Ae_{k-1}+\omega_k)^T]=E[Ae_{k-1}e_{k-1}^TA^T]+E[\omega_k\omega_k^T]
\]</span> 得到：</p>
<p><span class="math display">\[P_k^-=AP_{k-1}A^T+Q\]</span></p>
<p>到这步，卡尔曼滤波形成一个完整的理论闭环。</p>
<h3 id="离散线性卡尔曼滤波算法">离散线性卡尔曼滤波算法</h3>
<p>  卡尔曼滤波器采用反馈控制的方法来估计过程状态：滤波器估计过程某一时刻的状态，然后以（含噪声的）观测变量的方式获得反馈。因此卡尔曼滤波器可分为两个部分：</p>
<h4 id="时间更新方程"><code>时间更新方程</code></h4>
<p>  时间更新方程负责及时向前推算当前状态变量和误差协方差估计的值，以便为下一个时间状态构造先验估计，其数学表示如下：
<span class="math display">\[
\hat x_k^- = A \hat x_{k-1}+B\hat \mu_k+w_k \\
P_{k}^-=AP_{k-1}A^T+Q
\]</span></p>
<h4 id="测量更新方程"><code>测量更新方程</code></h4>
<p>  测量更新方程负责反馈——也就是说，它将先验估计
和新的测量变量结合以构造改进的后验估计，其数学表示如下：</p>
<p><span class="math display">\[K_k=P^-_kH^T(HP^-_kH^T+R)^{-1}\]</span></p>
<p><span class="math display">\[Z_k=Hx_k+v_k\]</span></p>
<p><span class="math display">\[\hat x = \hat x_k^{-}+K_k(Z_k-H\hat
x_k^{-})\]</span></p>
<p><span class="math display">\[P_k=(I-K_kH)P_k^{-}\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">离散线性卡尔曼滤波器的递归计算过程如下图：</span><br></pre></td></tr></table></figure>
<p><img src="1.jpg" alt="离散卡尔曼滤波的递归过程">
  时间更新方程将当前状态变量作为先验估计及时地向前投射到测量更新方程，测量更新方程校正先验估计以获得状态的后验估计。完成时间更新方程和测量更新方程的一轮更新之后，再次重复这个过程，将上一次计算得到的后验估计作为下一次计算的先验估计。</p>
<h4 id="卡尔曼滤波器参数分析">卡尔曼滤波器参数分析</h4>
<p>  在实现卡尔曼滤波器算法时，会涉及到很多参数，如下：</p>
<blockquote>
<p><span class="math inline">\(x_0\)</span>：动态系统的初始状态变量<span class="math inline">\(x_0\)</span>一般直接取第一个测量值<span class="math inline">\(z_0\)</span>；</p>
<p><span class="math inline">\(P_0\)</span>：系统初始状态变量<span class="math inline">\(x_0\)</span>的协方差，只要初始值不为零，初始协方差矩阵的取值对滤波效果影响很小，都能很快收敛；</p>
<p><span class="math inline">\(A\)</span>：状态转移矩阵，是根据经验对下一个时间周期目标状态的
一种预测。在某些情况下，这种预测是确定的，而另一些情况下
这种预测是未知的；</p>
<p><span class="math inline">\(B\)</span>：输入控制矩阵，作用在控制向量<span class="math inline">\(\mu_k\)</span>上的<span class="math inline">\(n\times1\)</span>输入控制矩阵，由于控制信息是已知的，一般很好确定；
<span class="math inline">\(H\)</span>：<span class="math inline">\(m\times n\)</span>观测模型矩阵，
负责将系统的真实状态映射到观测空间，根据动态系统很容易确定；</p>
<p><span class="math inline">\(P ^-\)</span>：为<span class="math inline">\(n\times n\)</span>先验估计误差协方差矩阵，由<span class="math inline">\(P_0\)</span>递归即可得到；</p>
<p><span class="math inline">\(P\)</span> ：为<span class="math inline">\(n×n\)</span>后验估计误差协方差矩阵，由<span class="math inline">\(P_0\)</span>递归即可得到；</p>
<p><span class="math inline">\(Q\)</span>：<span class="math inline">\(n\times n\)</span>过程噪声<span class="math inline">\(\omega_n\)</span>是的协方差矩阵
，当动态系统的状态转换过程确定时，<span class="math inline">\(Q\)</span>是一个确定的值，此时，可通过离线测试确定对于某个过程的最优<span class="math inline">\(Q\)</span>值，一般来说，当状态转换过程为已确定时，<span class="math inline">\(Q\)</span> 的取值越小越好。 当 <span class="math inline">\(Q\)</span>
取值逐渐增大时，滤波收敛变慢，且状态变量的扰动变大。当系统的动态转换过程是不确定的，随时间变化，此时<span class="math inline">\(Q\)</span>不再是一个确定值，而是一个随时间变化的变量<span class="math inline">\(Q(k)\)</span>，此时的卡尔曼滤波为自适应卡尔曼滤波，关于自适应卡尔曼滤波的更详细内容请参考此文—<a href="http://read.pudn.com/downloads76/ebook/285147/Paper/pdf/y8576770004.pdf">自适应卡尔曼滤波技术</a>，在此不做进一步展开；</p>
<p><span class="math inline">\(R\)</span>：<span class="math inline">\(m\times m\)</span>测量噪声<span class="math inline">\(v_n\)</span>协方差矩阵，
跟系统外部环境的测量仪器相关，一般很难获得改值，根据平时的使用经历来看:</p>
<blockquote>
<p><span class="math inline">\(R\)</span>取值过小或过大都会使滤波效果变差；</p>
<p><span class="math inline">\(R\)</span>取值越小收敛越快，反之收敛越慢；</p>
<p>一般离线得到合适的<span class="math inline">\(R\)</span>值，再代入滤波器中；</p>
</blockquote>
<p><span class="math inline">\(I\)</span>：<span class="math inline">\(n\times n\)</span> 单位矩阵</p>
<p><span class="math inline">\(K\)</span>:<span class="math inline">\(n×m\)</span>阶矩阵， 卡尔曼增益</p>
</blockquote>
<p>  关于卡尔曼滤波参数的更详细内容，由于篇幅有限，只做了简单的描述，但是卡尔曼滤波器参数的确定却是重中之重，直接影响到算法的效果，要进行实际应用的读者可结合<a href="http://file.elecfans.com/web1/M00/80/05/pIYBAFwnp8uAL-vDAAZFhhuu8y8385.pdf">卡尔曼滤波器参数分析与应用方法研究</a>一文，来做进一步讨论。</p>
<h3 id="发散现象及平方根滤波">发散现象及平方根滤波</h3>
<h4 id="发散现象">发散现象</h4>
<p>  线性卡尔曼滤波基于线性高斯状态空间模型的假设推导的，但是在实际应用时动态系统不一定完全满足这些假定，这会儿导致卡尔曼滤波的不稳定，这也叫卡尔曼滤波的发散现象，另外在计算时如果数值不太精确也会产生发散现象。</p>
<h4 id="平方根滤波">平方根滤波</h4>
<p>  一个数学上优美且计算可行的，解决卡尔曼滤波发散问题的方法是使用平方根滤波，其本质思想是对卡尔曼滤波进行修正，在算法的每一次循环中使用数值稳定的正交变换。具体而言，就是使用乔里斯基分解将卡尔曼滤波的误差协方差矩阵转换为其平方根形式。理论推导部分可以参考机械工业出版社的《神经网络与机器学习》
第十四章 动态系统状态估计的贝叶斯滤波
中的平方根滤波部分，在此不做推导。</p>
]]></content>
      <tags>
        <tag>卡尔曼滤波</tag>
        <tag>马尔可夫链</tag>
      </tags>
  </entry>
  <entry>
    <title>奇异值分解</title>
    <url>/posts/5a1d36e7/</url>
    <content><![CDATA[<p>  奇异值分解（Singular Value
Decomposition，SVD）是线性代数中一种重要的矩阵分解方法，区别于只适用于实对称矩阵的特征分解方法，奇异值分解可对任意实矩阵进行分解。
<span id="more"></span></p>
<h1 id="特征分解">特征分解</h1>
<p> 特征分解（eigendecomposition）又叫谱分解（Spectral
decomposition），是把一个矩阵根据其特征值和特征向量分解的过程，只有可以正交化的矩阵才可以进行特征分解。</p>
<blockquote>
<p><span class="math inline">\(A\)</span>为<span class="math inline">\(n\)</span>阶方阵，若存在<span class="math inline">\(n\)</span>维非零向量<span class="math inline">\(x\)</span>使得： <span class="math display">\[
Ax = \lambda x
\]</span> 则称<span class="math inline">\(\lambda\)</span>为矩阵<span class="math inline">\(A\)</span>的特征值，<span class="math inline">\(x\)</span>为<span class="math inline">\(A\)</span>属于<span class="math inline">\(\lambda\)</span>的特征向量（eigenvector）。</p>
</blockquote>
<p>  有了上述定义，接下来讨论如何计算一个矩阵的特征值和特征向量。由定义可知：</p>
<p><span class="math display">\[
Ax-\lambda x=0 \Rightarrow (A-\lambda I)x=0
\]</span></p>
<p>  其中<span class="math inline">\(I\)</span>为单位矩阵，显然上式的推导结果是一个<span class="math inline">\(n\)</span>元<span class="math inline">\(n\)</span>次的齐次线性方程组，<span class="math inline">\(x\)</span>为该方程组的一个非零解，则有$r(A-I)=r
&lt; n |A-I|=0 <span class="math inline">\(，其中\)</span>|A-I|=0<span class="math inline">\(称为\)</span>A<span class="math inline">\(的特征方程，\)</span>|A-I|<span class="math inline">\(称为\)</span>A$的特征多项式。基于此，可得到求解方阵A特征值和特征向量的步骤如下：</p>
<blockquote>
<p>1、计算方阵A的特征多项式<span class="math inline">\(|A-\lambda
I|\)</span>；</p>
<p>2、求出特征方程<span class="math inline">\(|A-\lambda
I|=0\)</span>的所有根（包括复根和重根），这些根<span class="math inline">\(\lambda_1,\lambda_2,\cdots,\lambda_n\)</span>即为<span class="math inline">\(A\)</span>的所有特征值；</p>
<p>3、对于<span class="math inline">\(A\)</span>的每一个特征值<span class="math inline">\(\lambda_i(1\leq i\leq
n)\)</span>，求解齐次线性方程组<span class="math inline">\((A-\lambda_i
I)x=0\)</span>，该方程组的每一个非零解都是<span class="math inline">\(A\)</span>属于特征值<span class="math inline">\(\lambda_i\)</span>的特征向量；</p>
</blockquote>
<p>  求出矩阵<span class="math inline">\(A\)</span>的特征值和特征向量后，若矩阵<span class="math inline">\(A\)</span>有<span class="math inline">\(n\)</span>个线性独立的特征向量，那么 <span class="math inline">\(A\)</span>是可以正交化的，此时 <span class="math inline">\(A\)</span></p>
<p><span class="math display">\[
A = WDW^{-1}
\]</span></p>
<p>其中<span class="math inline">\(W\)</span>时<span class="math inline">\(n\)</span>个特征向量所组成的<span class="math inline">\(n \times n\)</span>维矩阵，<span class="math inline">\(D\)</span>为以这<span class="math inline">\(n\)</span>个特征值为主对角线元素的对角阵。</p>
<h1 id="奇异值分解">奇异值分解</h1>
<ul>
<li><p>定义</p>
<blockquote>
<p>若<span class="math inline">\(M\)</span>为一个<span class="math inline">\(m \times
n\)</span>阶的矩阵，则存在一个分解，使得： <span class="math display">\[
M = UDV^T
\]</span> 其中<span class="math inline">\(U\)</span>为<span class="math inline">\(m\)</span>阶酉矩阵、<span class="math inline">\(V\)</span>为<span class="math inline">\(n\)</span>阶酉矩阵、<span class="math inline">\(D\)</span>为<span class="math inline">\(m\times
n\)</span>的非负实对角矩阵。称此分解为奇异值分解，一般我们将<span class="math inline">\(V\)</span>中的每一个特征向量叫做<span class="math inline">\(M\)</span>的右奇异向量，将<span class="math inline">\(U\)</span>中的每个特征向量叫做左奇异向量，<span class="math inline">\(D\)</span>对角线上的元素称为<span class="math inline">\(M\)</span>的奇异值，当规定奇异值降序排列时，可唯一确定一个<span class="math inline">\(D\)</span>。</p>
</blockquote>
<p>  有了定义，接下来需要确定奇异值分解的三个矩阵<span class="math inline">\(U、D、V\)</span>。比较直观的想法是通过<span class="math inline">\(M\)</span>来构造一个方阵来进行特征分解，间接计算<span class="math inline">\(U、D、V\)</span>，由于<span class="math inline">\(MM^T,M^TM\)</span>分别为<span class="math inline">\(m\times m\)</span>和<span class="math inline">\(n\times n\)</span>的方阵，则有： <span class="math display">\[
\begin{equation}
\begin{split}
MM^T=UDV^T(UDV^T)^T=UDV^TVD^TU^T = UDD^TU^T=U\sum_1 U^T \\
M^TM = (UDV^T)^TUDV^T=VD^TU^TUDV^T=VDD^TV^T=V\sum_2 V^T
\end{split}
\end{equation}
\]</span> 注意到： <span class="math display">\[
M = UDV^T \Rightarrow MV = UDV^TV \Rightarrow MV= UD \Rightarrow Mv_i =
\delta_iu_i \Rightarrow \delta_i = \frac{Mv_i}{u_i}
\]</span> 其中，<span class="math inline">\(v_i,u_i\)</span>分别为<span class="math inline">\(V,U\)</span>中第<span class="math inline">\(i\)</span>个特征向量。这个式子提供了一种计算奇异值的方法，另一种思路是结合式（5）：
<span class="math display">\[
\sum = DD^T=D^2 \Rightarrow \delta_i = \sqrt{\lambda_i}
\]</span> 即，特征值矩阵为奇异值矩阵的平方，故可以通过计算<span class="math inline">\(M^TM\)</span>的特征值取平方根来计算奇异值。</p></li>
<li><p>SVD的计算步骤</p>
<blockquote>
<p>1.计算<span class="math inline">\(MM^T\)</span>和<span class="math inline">\(M^TM\)</span>；</p>
<p>2.分别计算<span class="math inline">\(MM^T\)</span>和<span class="math inline">\(M^TM\)</span>的特征向量和特征值；</p>
<p>3.<span class="math inline">\(MM^T\)</span>的特征向量组成<span class="math inline">\(U\)</span>，而<span class="math inline">\(M^TM\)</span>的特征向量组成<span class="math inline">\(V\)</span>；</p>
<p>4.对<span class="math inline">\(MM^T\)</span>和<span class="math inline">\(M^TM\)</span>的非零特征值求平方根，对应上述特征向量的位置，填入对角阵<span class="math inline">\(D\)</span>的位置；</p>
</blockquote></li>
<li><p>计算示例</p>
<p>  接下来以计算矩阵<span class="math inline">\(A=\begin{pmatrix}0&amp;1 \\ 1&amp;  1
\\1&amp;0\end{pmatrix}\)</span>的奇异值分解为例，来进一步熟悉：</p>
<p>第一步，先计算<span class="math inline">\(A\)</span>的两个转置积：
<span class="math display">\[
\begin{equation}
\begin{split}
&amp;A^TA=\begin{pmatrix} 0 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 0
\end{pmatrix}\begin{pmatrix}  0 &amp; 1 \\ 1 &amp; 1 \\ 1 &amp;
0\end{pmatrix} = \begin{pmatrix}2 &amp; 1 \\ 1&amp; 2\end{pmatrix} \\
&amp;AA^T = \begin{pmatrix}0 &amp; 1 \\ 1 &amp; 1 \\ 1 &amp;
0\end{pmatrix}\begin{pmatrix}0 &amp; 1 &amp;1 \\ 1 &amp; 1 &amp;
0\end{pmatrix}=\begin{pmatrix}1 &amp; 1 &amp; 0 \\ 1 &amp; 2 &amp; 1 \\
0 &amp; 1 &amp; 1\end{pmatrix}
\end{split}
\end{equation}
\]</span> 第二步，分别计算两个转置积的特征值和特征向量： <span class="math display">\[
\begin{equation}
\begin{split}
&amp;\color{#F00}{(A^TA-\lambda I)x = 0} \Rightarrow
|A^TA-\lambda I|=0
\\
&amp;\Rightarrow
\begin{vmatrix}
2-\lambda &amp; 1 \\
1 &amp; 2-\lambda
\end{vmatrix} = 0 \Rightarrow \lambda^2-4\lambda+3=0
\end{split}
\end{equation}
\]</span> 容易得到式（9）中一元二次方程的根为<span class="math inline">\(\lambda_1 = 3,\lambda_2=1\)</span>，当<span class="math inline">\(\lambda=3\)</span>时，将特征根分别带入式（1）中，得到：
<span class="math display">\[
\begin{equation}
\begin{split}
&amp;&amp;(A^TA-3I)x = 0 \Rightarrow\begin{pmatrix}-1 &amp; 1 \\ 1 &amp;
-1\end{pmatrix}x=  0 \Rightarrow\begin{pmatrix}-1 &amp; 1 \\ 1 &amp;
-1\end{pmatrix}\begin{pmatrix}x_1 \\ x_2\end{pmatrix}=  0 \\
\end{split}
\end{equation}
\]</span> 此时的单位特征向量为： <span class="math display">\[
x_{\lambda=3} = \begin{pmatrix} \frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}}\end{pmatrix}
\]</span> 同理得到： <span class="math display">\[
x_{\lambda=1} = \begin{pmatrix} \frac{1}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}}\end{pmatrix}
\]</span> 同理计算<span class="math inline">\(AA^T\)</span>的特征根和特征向量： <span class="math display">\[
\begin{equation}
\begin{split}
&amp;\lambda_1=3，u_1=
\begin{pmatrix}
\frac{1}{\sqrt{6}} \\ \frac{2}{\sqrt{6}} \\ \frac{1}{\sqrt{6}}
\end{pmatrix}；
&amp;\lambda_2 = 1，u_2 =
\begin{pmatrix}
\frac{1}{\sqrt{2}} \\ 0 \\ -\frac{1}{\sqrt{2}}
\end{pmatrix}；
&amp;\lambda_3 = 0，u_3 =
\begin{pmatrix}
\frac{1}{\sqrt{3}} \\ -\frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{3}}
\end{pmatrix}
\end{split}
\end{equation}
\]</span></p>
<p>第三步，使用两个转置积的单位特征向量构造<span class="math inline">\(U,V\)</span>矩阵： <span class="math display">\[
\begin{equation}
\begin{split}
&amp;U =(u_1,u_2,u_3)=
\begin{pmatrix}
\frac{1}{\sqrt{6}} &amp; \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{3}} \\
\frac{2}{\sqrt{6}} &amp; 0 &amp; -\frac{1}{\sqrt{3}} \\
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{3}}
\end{pmatrix} \\
&amp;V^T = (v_1,v_2)^T=
\begin{pmatrix}
\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}
\end{pmatrix}
\end{split}
\end{equation}
\]</span> 第四步，计算奇异值，直接使用<span class="math inline">\(\delta_i =
\sqrt{\lambda_i}\)</span>计算奇异值并组成对角阵<span class="math inline">\(D\)</span>： <span class="math display">\[
D =
\begin{pmatrix}
\sqrt{3} &amp; 0\\
0 &amp; 1\\
0 &amp; 0
\end{pmatrix}
\]</span> 最终得到矩阵<span class="math inline">\(A\)</span>的奇异值分解： <span class="math display">\[
A= UDV^T
=\begin{pmatrix}
\frac{1}{\sqrt{6}} &amp; \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{3}} \\
\frac{2}{\sqrt{6}} &amp; 0 &amp; -\frac{1}{\sqrt{3}} \\
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{3}}
\end{pmatrix}\begin{pmatrix}
\sqrt{3} &amp; 0\\
0 &amp; 1\\
0 &amp; 0
\end{pmatrix}
\begin{pmatrix}
\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}
\end{pmatrix}
\]</span></p></li>
</ul>
<h1 id="应用">应用</h1>
<p>  对于奇异值,它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。也就是说，我们也可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵：
<span class="math display">\[
A_{m \times n} = U_{m \times m}D_{m \times n}V^T_{n \times n} \approx
U_{m \times k} D_{k \times k} V^T_{k \times n}
\]</span> 这样处理的好处是，我们可以用三个较小的矩阵<span class="math inline">\(U_{m \times k},D_{k \times k},V_{k \times
n}^T\)</span>来表示一个大矩阵<span class="math inline">\(A\)</span>，如下图所示，使用三个灰色部分的小矩阵来表示大矩阵。</p>
<figure>
<img src="https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170105140822191-1774139119.png" alt="图片来源于刘建平Pinard">
<figcaption aria-hidden="true">图片来源于<a href="https://www.cnblogs.com/pinard/p/6251584.html">刘建平Pinard</a></figcaption>
</figure>
<p>  由于这个重要的性质，SVD可以用于PCA降维，来做图片数据压缩和去噪。也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。同时也可以用于NLP中的算法，比如潜在语义索引（LSI）。</p>
<blockquote>
<p>Note：</p>
<p>  需要注意的是，奇异值分解中特征值的求解是比较核心的地方，在工程应用中，往往需要进行奇异值分解都是大矩阵，对这类大矩阵，如果采用上面的方法求解特征值需要花费较多的时间和资源。对此，可以采用<a href="https://liangjiandeng.github.io/teaching/Numer_Analy/Chap24.pdf">乘幂法</a>和<a href="https://liangjiandeng.github.io/teaching/Numer_Analy/Chap24.pdf">反幂法</a>或者QR方法来近似求解矩阵的特征根，在此不做进一步展开，有兴趣的读者可以进一步了解一下。</p>
</blockquote>
<h1 id="基本概念说明">基本概念说明</h1>
<ul>
<li><p>矩阵的子式</p>
<p>  设有<span class="math inline">\(m \times n\)</span>矩阵A，在<span class="math inline">\(A\)</span>中任意取定<span class="math inline">\(k\)</span>个行和<span class="math inline">\(k\)</span>个列（<span class="math inline">\(k \leq
\min\{m,n\}\)</span>），位于这些行与列交叉处的元素按原来的相对顺序排成一个<span class="math inline">\(k\)</span>阶行列式，称它为矩阵<span class="math inline">\(A\)</span>的一个<span class="math inline">\(k\)</span>阶子式，特别地，<span class="math inline">\(A\)</span>中每一个元素就是<span class="math inline">\(A\)</span>的一阶子式。 　　对于确定的<span class="math inline">\(k\)</span>，在<span class="math inline">\(m \times
n\)</span>矩阵<span class="math inline">\(A\)</span>中，总共有<span class="math inline">\(C_m^k \times C_n^k\)</span>个<span class="math inline">\(k\)</span>阶子式，这些子式的值有的可能是零，也可能不为零，把值不为零的子式称为非零子式。</p></li>
<li><p>矩阵的秩</p>
<p>  在<span class="math inline">\(m\times n\)</span>矩阵<span class="math inline">\(A\)</span>中，非零子式的最高阶数称为矩阵<span class="math inline">\(A\)</span>的秩，记为<span class="math inline">\(r(A)\)</span>或秩规定零矩<span class="math inline">\((A)\)</span>,规定零矩阵的秩为零。</p>
<blockquote>
<p>推论1：</p>
<p><span class="math inline">\(r(A)=r
\Leftrightarrow  A\)</span>中所有<span class="math inline">\(r+1\)</span>阶子式（如果有的话）全为零，而<span class="math inline">\(A\)</span>中至少有一个<span class="math inline">\(r\)</span>阶子式非零。</p>
</blockquote></li>
<li><p>矩阵的谱半径</p>
<p>  <span class="math inline">\(A\)</span>为<span class="math inline">\(n\)</span>阶方阵，<span class="math inline">\(\lambda_i（1\leq i\leq
n）\)</span>为其特征值，则<span class="math inline">\(A\)</span>的谱半径定义如下： <span class="math display">\[
\rho(r) = max\{|\lambda_1|,|\lambda_2|,\dots,|\lambda_n|\}
\]</span> 即方阵<span class="math inline">\(A\)</span>的谱半径为<span class="math inline">\(A\)</span>特征值中绝对值最大的那个值。</p></li>
<li><p>正定矩阵</p>
<p>  如果对于所有的非零实系数向量 <span class="math inline">\(z\)</span>，都有 <span class="math inline">\(z^TAz&gt;0\)</span>，则称矩阵 <span class="math inline">\(A\)</span> 是正定的。正定矩阵的行列式必然大于0，
所有特征值也必然大于0。相对应的，半正定矩阵的行列式必然 ≥ 0。</p></li>
<li><p>正交矩阵</p>
<p>  若一个方阵其行与列皆为正交的单位向量（即二者的内积为0），则该方阵为正交矩阵。</p></li>
<li><p>酉矩阵</p>
<p>  酉矩阵（unitary matrix）是一种特殊的方阵，它满足<span class="math inline">\(UU^H=U^HU=I_n\)</span>（<span class="math inline">\(U^H\)</span>为<span class="math inline">\(U\)</span>的共轭转置，其在转置的基础上，增加了复数的共轭）。酉矩阵实际上是推广的正交矩阵（orthogonal
matrix）；当酉矩阵中的元素均为实数时，酉矩阵实际就是正交矩阵。另一方面，由于<span class="math inline">\(U^{-1}U=UU^{-1}=I_n\)</span>，所以酉矩阵 <span class="math inline">\(U\)</span>满足$
U<sup>{−1}=U</sup>H$；事实上，这是一个矩阵是酉矩阵的充分必要条件。</p></li>
<li><p>正规矩阵</p>
<p>  同酉矩阵一样，正规矩阵（normal
matrix）也是一种特殊的方阵，它要求在矩阵乘法的意义下与它的共轭转置矩阵满足交换律，即<span class="math inline">\(MM^H=M^HM\)</span>。显然，复系数的酉矩阵和实系数的正交矩阵都是正规矩阵。</p></li>
<li><p>谱定理和谱矩阵</p>
<p>  矩阵的对角化是线性代数中的一个重要命题。谱定理（spectral
theorem）给出了方阵对角化的一个结论：若矩阵<span class="math inline">\(M\)</span>是一个正规矩阵，则存在酉矩阵 <span class="math inline">\(U\)</span>，以及对角矩阵 <span class="math inline">\(\sum\)</span>，使得<span class="math inline">\(M=U\sum
U^H\)</span>。也就是说，正规矩阵，可经由酉变换，分解为对角矩阵；这种矩阵分解的方式，称为谱分解（spectral
decomposition）。</p>
<hr>
<h1 id="参考文章">参考文章</h1>
<ul>
<li><a href="https://www.cnblogs.com/pinard/p/6251584.html">奇异值分解原理与在降维中的应用</a></li>
<li><a href="https://bainingchao.github.io/2018/10/11/%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3SVD%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/">一步步教你轻松学奇异值分解SVD降维算法</a></li>
<li><a href="https://yanfei.site/docs/statscompbook/matrices.html#%E5%B9%82%E6%96%B9%E6%B3%95power-method">统计计算-奇异值分解</a></li>
</ul></li>
</ul>
]]></content>
      <tags>
        <tag>svd</tag>
        <tag>特征分解</tag>
        <tag>特征向量</tag>
      </tags>
  </entry>
  <entry>
    <title>机器视觉之基本概念</title>
    <url>/posts/781628f/</url>
    <content><![CDATA[<p>  主要记录机器视觉领域的一些基本概念及一些实践中的tricks。
<span id="more"></span></p>
<h2 id="ccd">CCD</h2>
<p>  CCD（Charge-Coupled
Device）即电荷耦合器件,通常称为CCD图像传感器，是一种半导体器件，当入射光线照射到CCD芯片上的感光单元（微小光敏物质，即像素（Pixel）），光子会被转为电子，这些电子在像素内累计形成电荷。一块CCD芯片上包含的感光单元越多，其成像分辨率也就越高。其成像过程如下：</p>
<ul>
<li><p>光电转换</p>
<p>入射光线通过光电二极管转换为电荷</p></li>
<li><p>电荷积累</p>
<p>光敏元件根据光强的不同积累不同数量的电荷</p></li>
<li><p>电荷转移</p>
<p>通过电荷转移机制，逐行、逐列将电荷移至输出放大器</p></li>
<li><p>电压转换</p>
<p>输出放大器将电荷信号转为电压信号，并传递给模数转换器（ADC），生成数字图像数据</p></li>
</ul>
<h2 id="cmos">CMOS</h2>
<p>  CMOS（Complementary Metal-Oxide
Semiconductor，互补金属氧化物半导体）成像原理与CCD成像原理类似，但CMOS成像器件的电荷转移和电压转换过程在同一块硅片上完成，因此CMOS成像器件的结构更加简单，成本更低，功耗更低，适用于高分辨率、低功耗的成像应用。</p>
<p>CCD与CMOS成像器件的对比如下：</p>
<table>
<thead>
<tr>
<th style="text-align: center;">特性</th>
<th style="text-align: center;">CCD</th>
<th style="text-align: center;">CMOS</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">图像质量</td>
<td style="text-align: center;">高、噪声低，均匀性好</td>
<td style="text-align: center;">略低，噪声高</td>
</tr>
<tr>
<td style="text-align: center;">制造成本</td>
<td style="text-align: center;">高</td>
<td style="text-align: center;">低</td>
</tr>
<tr>
<td style="text-align: center;">功耗</td>
<td style="text-align: center;">高</td>
<td style="text-align: center;">低</td>
</tr>
<tr>
<td style="text-align: center;">读取速度</td>
<td style="text-align: center;">较慢</td>
<td style="text-align: center;">快</td>
</tr>
<tr>
<td style="text-align: center;">动态范围</td>
<td style="text-align: center;">宽</td>
<td style="text-align: center;">较窄</td>
</tr>
<tr>
<td style="text-align: center;">弱光性能</td>
<td style="text-align: center;">优</td>
<td style="text-align: center;">稍弱</td>
</tr>
</tbody>
</table>
<p>通常来说，CCD通常用于高端相机、科学研究和天文观测等对图像质量要求极高的领域，而CMOS则广泛应用于消费类设备（如智能手机摄像头）、监控设备和工业检测等场景，其成本低、功耗低和速度快更具优势。需要注意的是由于CCD采用全局曝光，而CMOS相机使用卷帘曝光，所以在拍摄运动目标时，优先考虑CCD传感器。</p>
<blockquote>
<p>Note 1.
全局曝光是传感器上所有像素在同一时刻开启曝光并在同一时刻曝光结束，将物体某时刻的状态成像，对运动物体而言，类似于将物体冻结了，所以适合拍摄高速运动的物体。</p>
</blockquote>
<blockquote>
<p>Note 2.
卷帘曝光是逐行（hang）顺序开启曝光，不同行间曝光的开启时刻有个很小的延迟，所以不适合运动物体的拍摄。</p>
</blockquote>
<h2 id="像素">像素</h2>
<p>  像素是构成数字图像的基本单位，相机靶面上的一个感光单元为一个像素，每个像素点都拥有色调和嫉恶调等色彩信息，规则排列的像素集合可以形成一张完整的图像。</p>
<h2 id="像素直径">像素直径</h2>
<p>  像素直径，也称像元尺寸指每个CCD元件的大小，通常使用<span class="math inline">\(\mu
m\)</span>作为单位，严谨的说，此处的大小中包含了感光单元和信号传输通路，其与像素间距（即某个像素的中心到邻近一个像素的中心的距离）相同。如果像素直径较小，则图像将通过较小的像素进行描绘，因此可以获得更加精细的图像，显然通过像素间距和有效像素数可以直接求出CCD元件中感光区域的大小（即CCD元件的总面积）</p>
<h2 id="相机靶面尺寸">相机靶面尺寸</h2>
<p>  相机靶面尺寸指用于接收光信号的传感器的尺寸，指的是传感器（工作区域为矩形）对角线长度。一般分为采用英寸单位表示和采用APS-C大小等规格表示这2种方式。采用英寸表示时，该尺寸并不是拍摄的实际尺寸，而是相当于摄像管的对角长度。比如1/2英寸的CCD表示<strong>拥有相当于1/2英寸的摄像管的拍摄范围</strong>。z之所以会如此计算，是由于当初制造CCD的目的就是用于代替电视机、录像机的摄像管。而想要继续使用镜头等光学器件的需求比较强烈，由此诞生了这种奇怪的规格，主要的英寸规格如下表所示。</p>
<table>
<thead>
<tr>
<th style="text-align: center;">尺寸(英寸)</th>
<th style="text-align: center;">对角长度(mm)</th>
<th style="text-align: center;">拍摄区域(wxh,mm)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2/3</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">8.8x6.6</td>
</tr>
<tr>
<td style="text-align: center;">1/2</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">6.4x4.8</td>
</tr>
<tr>
<td style="text-align: center;">1/3</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">4.8x3.6</td>
</tr>
<tr>
<td style="text-align: center;">1/4</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;">3.6x2.0</td>
</tr>
</tbody>
</table>
<h2 id="快门速度">快门速度</h2>
<p>  快门速度在工业视觉中也称为曝光时间，表示CCD或CMOS感光元件中积累电荷的时间，单位为秒。快门速度越快，感光元件中积累电荷的时间越短，图像的亮度越低，图像的细节越少，图像的噪点越多。快门速度越慢，感光元件中积累电荷的时间越长，图像的亮度越高，图像的细节越多，图像的噪点越少。直观来看，快门速度可以用于调整光量。</p>
<h2 id="曝光值">曝光值</h2>
<p>  曝光值（EV，Exposure
Value）是用于衡量图像整体亮度的一个综合指标，由一下三个主要因素决定：</p>
<ul>
<li>快门速度</li>
</ul>
<p>  控制光线进入的时间，决定了运动模糊的程度，曝光时间过长，如果相机的感光元件在曝光期间，被拍摄的物体发生了运动，导致在单帧中记录下了物体的移动轨迹。</p>
<ul>
<li>光圈（F值）</li>
</ul>
<p>  控制进入光线的量，决定了相机的景深</p>
<ul>
<li>感光度(ISO)</li>
</ul>
<p>  控制感光元件对光线的灵敏度</p>
<p>其定义公式如下： <span class="math display">\[
E_v = \log_2 \frac{N^2}{t}
\]</span></p>
<h2 id="增益">增益</h2>
<p>  增益，是指将图像信号进行电子增幅的过程，增益越大，图像的亮度越高，但噪声也会随之增加。在暗区拍摄图像时，往往通过增加增益来提高图像的亮度，但也会导致图像噪声的增加。因此，在拍摄图像时，需要根据实际情况合理选择增益值，以达到最佳的图像质量。</p>
<h2 id="面阵相机">面阵相机</h2>
<p>  面阵相机（Area Scan
Camera）指感光单元（像素）按矩阵形式排列的相机，其一次拍摄即可捕获整个二维图像，常见视觉检测场景基本都是使用面阵相机，也常用于结构光三维重建。</p>
<h2 id="线阵相机">线阵相机</h2>
<p>  线阵相机（Line Scan
Camera）指感光单元（像素）按线性形式排列的相机，其一次拍摄只能捕获一行图像，成像时，需要通过移动相机或被检测物体来获取整个二维图像。相较于面阵相机，其拥有更高的分辨率，成像质量更高，同时需要配合编码器来配合触发拍照，并使用线型光源，常用于纸张、纺织品、金属板等表面缺陷检测场景。</p>
<h2 id="通讯方式">通讯方式</h2>
<h3 id="usb接口">USB接口</h3>
<p>  支持热插拔、标准统一，可连接多个设备，同时相机也可以通过USB线缆供电</p>
<h3 id="gige千兆以太网接口">Gige千兆以太网接口</h3>
<p>  可以简单方便的进行多相机设置，支持100米线材输出，是一种基于千兆以太网通信协议开发的相机接口标准</p>
<h3 id="cameralink接口">Cameralink接口</h3>
<p>  专门针对高速图像数据传输设计的通讯接口，是一种串行通讯协议，采用LVDS接口标准，传输速度快、抗干扰能力强、功耗低。</p>
<h2 id="工作距离wd">工作距离（WD）</h2>
<p>  指的是镜头的最下端到景物之间的距离。一般的镜头是可以看到无限远的，也就是说是没有上限的。</p>
<figure>
<img src="1.png" alt="相机成像结构">
<figcaption aria-hidden="true">相机成像结构</figcaption>
</figure>
<h2 id="视场角fov">视场角（FOV）</h2>
<p>  指镜头所能覆盖的范围。(相机实际拍摄到的区域尺寸)一个摄像机镜头能涵盖多大范围的景物，通常以角度来表示，这个角度就叫镜头的视角FOV。焦距越长，FOV越小，焦距越短，FOV越大</p>
<h2 id="光圈">光圈</h2>
<p>  光圈是一个用来控制光线透过镜头进入机身内感光面光量的装置。当光线不足时，我们把光圈调大，自然可以让更多光线进入相机，反之亦然。一般通过调整通光孔径大小来调节光圈，完整的光圈数值系列如下：F1，F1.4，F2，F2.8，F4，F5.6，F8，F11，F16，F22，F32，F44，F64。用F表示，以【镜头焦距f和通光孔径D的比值】(即，相对孔径的倒数，也就是“焦距÷有效孔径”)来衡量，每个镜头上都标有最大F值，例如：8mm/F1.4代表最大孔径D为5.7mm.
&gt; F值越小、光圈越大、进光量越大；F值越大、光圈越小、进光量越小。</p>
<h2 id="焦距">焦距</h2>
<p>  焦距就是镜头到成像面的距离，比如：50mm镜头，8mm镜头还是75mm镜头等。这些就是镜头到成像面的距离，也就是焦距，单位是毫米。
&gt;
焦距的大小决定着视角大小，焦距越大，视角越小，观察范围越小；焦距越小，视角越大，观察范围也越大</p>
<figure>
<img src="2.png" alt="相机成像结构">
<figcaption aria-hidden="true">相机成像结构</figcaption>
</figure>
<h2 id="景深">景深</h2>
<p>  景深与视野相似，不同的是景深指的是纵深的范围，视野指的是横向的范围。在最小工作距离到最大工作距离之间的范围称为景深，景深内的物体都可以清晰成像。景深一般可以通过光圈调节，光圈越小，景深越大。景深与镜头使用光圈、镜头焦距、拍摄距离以及对像质的要求(表现为对容许弥散圆的大小)有关。在假定其它条件不变的情况下：</p>
<ul>
<li>光圈越大，景深越小；光圈越小，景深越大</li>
<li>镜头焦距越长，景深越小；焦距越短，景深越大</li>
<li>拍摄距离越远，景深越大；距离越近，景深越小</li>
</ul>
<p>  总而言之，对于对景深有要求的项目，尽可能使用小的光圈；在选择放大倍率的镜头时，在项目许可下尽可能选用低倍率镜头。如果项目要求比较苛刻时，倾向选择高景深的尖端镜头。</p>
]]></content>
      <tags>
        <tag>相机</tag>
        <tag>视觉</tag>
        <tag>图像</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM之余弦退火学习率</title>
    <url>/posts/19c3723a/</url>
    <content><![CDATA[<p>  学习率这个概念在非线性优化中经常出现，在深度学习中模型在反向传播阶段严重依赖于损失函数梯度的链式传播，为了更好的控制参数更新的步长，引入了学习率的概念：
<span class="math display">\[
w_{new} = w_{old} - \eta \ \Delta J(w)
\]</span></p>
<span id="more"></span>
<p>  其中的<span class="math inline">\(\eta\)</span>为学习率，直观来说，非线性优化的过程就像下山，学习率就是步长，步子迈的太大或太小都不太理想。当步子迈得的太大了，你可能就直接跨过山脚，对应到模型训练中，就是学习率太高，每次更新参数时，跳过了最小值，导致在最优值附近来回振荡，无法收敛;步子太小，则需要走很久，才能到达山脚，对应到模型训练中，就是学习率太低，模型收敛的速度很慢，需要较长时间的训练才能收敛到最优值。举这个经典的下山的例子是为了说明学习率在模型训练中的重要意义。
  在深度学习的模型训练中学习率有很多使用策略，包括不限于：</p>
<ul>
<li>固定学习率</li>
</ul>
<p>  顾名思义就是在模型训练过程中使用固定学习率来进行模型训练，这样会难以平衡初期的收敛速度和后期的精细调整，一般很少使用，只在一些简单问题上应用。</p>
<ul>
<li>阶梯式衰减学习率（step decay）</li>
</ul>
<p>  指学习率在模型训练的特定步骤中衰减，会导致学习率变化不平滑，模型训练不稳定。</p>
<ul>
<li>指数衰减学习率（exponential decay）</li>
</ul>
<p>  指学习率在模型训练过程中按指数函数衰减，由于指数函数的高增长特性，前期往往能快速收敛，但是后期由于学习率衰减过快，导致训练停滞，收敛速度很慢。</p>
<ul>
<li>线性预热+线性衰减</li>
</ul>
<p>  指学习率在模型训练过程中先线性增加再线性较少，此方案在大语言模型的预训练被广泛使用，缺点在于是线性变化，变化不太平滑。</p>
<ul>
<li>余弦退火学习率（Cosine Annealing）</li>
</ul>
<p>  余弦退火学习率的公式如下： <span class="math display">\[
\eta_{t} = \eta_{min} + \frac{1}{2}(\eta_{max} -
\eta_{min})(1+\cos(\frac{t}{T}\pi))
\]</span>   其中，<span class="math inline">\(\eta_{t}\)</span>是第<span class="math inline">\(t\)</span>步的学习率，<span class="math inline">\(\eta_{min}\)</span>是训练过程中能接受的最小学习率，<span class="math inline">\(\eta_{max}是最大学习率\)</span>，<span class="math inline">\(t\)</span>为当前的训练步树，<span class="math inline">\(T\)</span>该epoch中的总训练步数。从公式可以看出，在训练的开始阶段，学习率解决最大值，模型的收敛速度较快，到达一定训练步数后，学些率开始减少，模型会在更小的参数空间内搜索最优值，随着训练步数的增长，学习率逐渐逼近最小值，模型在最优值附近的参数空间内搜索。</p>
<p>  同时学习率是按照余弦曲线的方式进行更新，变化平滑的同时，不会出现变化幅度不大。目前基于余弦退火学习率衍生出一些更精细的学习率调度算法，如：</p>
<ul>
<li><p>带热重启的余弦退火</p>
<p>  学习率在训练过程中周期性回到最大值，然后再次降低，公式如下：</p>
<p><span class="math display">\[
  \eta_{t} = \eta_{min} + \frac{1}{2}(\eta_{max} -
\eta_{min})(1+\cos(\frac{T_{cur}}{T_i}\pi))
  \]</span>   其中，<span class="math inline">\(T_{cur}\)</span>是自上次热重启之后的训练步数，<span class="math inline">\(T_i\)</span>是当前周期的总步数。这种学习率调度方式有助于跳出局部最优解，探索更广阔的参数空间</p></li>
<li><p>带预热的余弦退火</p>
<p>  带预热的余弦退火通过两阶段学习率调整实现：</p>
<ul>
<li><p>​预热阶段</p>
<p>训练初期学习率从较小值线性或非线性增长至预设的最大值，避免随机初始化权重下的大幅度参数更新引发振荡。</p></li>
<li><p>余弦退火阶段</p>
<p>  预热完成后，学习率按余弦函数周期性衰减，从最大值逐渐降至最小值，数学公式如下：
<span class="math display">\[
  \eta_{t}=
  \begin{cases}
  \eta_{start} + \dfrac{t}{T_{warmup}}(\eta_{max} -
\eta_{start})    \qquad 0 \leq t &lt; T_{warmup} \\
  \eta_{max} + \frac{1}{2}(\eta_{max} -
\eta_{min})(1+cos(\frac{t}{T_{cos}}\pi))  \qquad t \geq T_{warmup}
  \end{cases}
  \]</span> <span class="math inline">\(T_{warmup}\)</span>为预热步数，<span class="math inline">\(T_{cos}\)</span>为退火周期</p></li>
</ul></li>
<li><p>循环余弦退火（cyclical cosine annealing）</p>
<p>  顾名思义，就是在模型训练过程中，学习率的变化在余弦退火的基础上存在多个余弦周期，通过重启（Restart）机制恢复学习率至最大值，形成多周期探索-利用循环，可以平衡梯度在参数空间的探索与利用，避免剧烈波动。</p></li>
</ul>
<p>  余弦退火学习率策略通过平滑地调整学习率，帮助模型在训练初期快速收敛，在训练后期精细调整参数，从而找到更好的局部最优解。它的提出和发展极大地推动了深度学习模型训练的稳定性和效率，已成为现代深度学习训练的标准配置之一。</p>
<p>  虽然它不是万能的解决方案，但在大多数深度学习任务中，特别是大型语言模型的训练中，余弦退火都能提供显著的性能提升。通过理解其工作原理和适用边界，我们可以更好地利用这一强大工具，提高模型训练效果。</p>
<blockquote>
<p>编程实现</p>
</blockquote>
<ul>
<li><p>demo 1 <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">from torch.optim.lr_scheduler <span class="keyword">import</span> CosineAnnealingLR</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"># 创建模型和优化器</span><br><span class="line">model = <span class="built_in">MyModel</span>()</span><br><span class="line">optimizer = torch.optim.<span class="built_in">Adam</span>(model.<span class="built_in">parameters</span>(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"># 创建余弦退火调度器</span><br><span class="line"># T_max是半个周期的长度，通常设为总训练步数</span><br><span class="line"># eta_min是最小学习率</span><br><span class="line">scheduler = <span class="built_in">CosineAnnealingLR</span>(optimizer, T_max=<span class="number">1000</span>, eta_min=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line"># 在训练循环中使用</span><br><span class="line"><span class="keyword">for</span> epoch in <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch in data_loader:</span><br><span class="line">        # 训练步骤</span><br><span class="line">        optimizer.<span class="built_in">zero_grad</span>()</span><br><span class="line">        outputs = <span class="built_in">model</span>(inputs)</span><br><span class="line">        loss = <span class="built_in">criterion</span>(outputs, targets)</span><br><span class="line">        loss.<span class="built_in">backward</span>()</span><br><span class="line">        optimizer.<span class="built_in">step</span>()</span><br><span class="line">        </span><br><span class="line">        # 更新学习率</span><br><span class="line">        scheduler.<span class="built_in">step</span>()</span><br></pre></td></tr></table></figure></p></li>
<li><p>demo 2 <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">import</span> math</span></span><br><span class="line"><span class="function">def <span class="title">get_cosine_lr</span><span class="params">(current_step, total_steps, max_lr, min_lr)</span>:</span></span><br><span class="line"><span class="function">    <span class="string">&quot;&quot;</span><span class="string">&quot;计算当前步骤的余弦退火学习率&quot;</span><span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="function">    return min_lr + <span class="number">0.5</span> * (max_lr - min_lr) * (<span class="number">1</span> + math.cos(math.pi * current_step / total_steps))</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"># 在训练循环中使用</span></span><br><span class="line"><span class="function">max_lr =</span> <span class="number">0.001</span></span><br><span class="line">min_lr = <span class="number">0.0001</span></span><br><span class="line">total_steps = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step in <span class="built_in">range</span>(total_steps):</span><br><span class="line">    # 计算当前学习率</span><br><span class="line">    current_lr = <span class="built_in">get_cosine_lr</span>(step, total_steps, max_lr, min_lr)</span><br><span class="line">    </span><br><span class="line">    # 更新优化器的学习率</span><br><span class="line">    <span class="keyword">for</span> param_group in optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = current_lr</span><br><span class="line">    </span><br><span class="line">    # 正常的训练步骤</span><br><span class="line">    optimizer.<span class="built_in">zero_grad</span>()</span><br><span class="line">    outputs = <span class="built_in">model</span>(inputs)</span><br><span class="line">    loss = <span class="built_in">criterion</span>(outputs, targets)</span><br><span class="line">    loss.<span class="built_in">backward</span>()</span><br><span class="line">    optimizer.<span class="built_in">step</span>()</span><br></pre></td></tr></table></figure></p></li>
<li><p>demo 3</p>
<p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">from torch.optim.lr_scheduler <span class="keyword">import</span> CosineAnnealingWarmRestarts</span><br><span class="line"></span><br><span class="line"># 创建带热重启的余弦退火调度器</span><br><span class="line"># T_0是第一次重启前的迭代次数</span><br><span class="line"># T_mult是控制重启周期如何变化的因子</span><br><span class="line">scheduler = <span class="built_in">CosineAnnealingWarmRestarts</span>(</span><br><span class="line">    optimizer, </span><br><span class="line">    T_0=<span class="number">1000</span>,  # 第一个周期的长度</span><br><span class="line">    T_mult=<span class="number">2</span>,  # 每次重启后周期长度翻倍</span><br><span class="line">    eta_min=<span class="number">0.0001</span>  # 最小学习率</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 在训练循环中使用</span><br><span class="line"><span class="keyword">for</span> epoch in <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch in data_loader:</span><br><span class="line">        # 训练步骤</span><br><span class="line">        optimizer.<span class="built_in">zero_grad</span>()</span><br><span class="line">        outputs = <span class="built_in">model</span>(inputs)</span><br><span class="line">        loss = <span class="built_in">criterion</span>(outputs, targets)</span><br><span class="line">        loss.<span class="built_in">backward</span>()</span><br><span class="line">        optimizer.<span class="built_in">step</span>()</span><br><span class="line">        </span><br><span class="line">        # 更新学习率</span><br><span class="line">        scheduler.<span class="built_in">step</span>()</span><br></pre></td></tr></table></figure></p></li>
</ul>
]]></content>
      <tags>
        <tag>LLM</tag>
        <tag>学习率</tag>
        <tag>模型训练</tag>
        <tag>余弦退火</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM之模型训练Tricks</title>
    <url>/posts/15775e35/</url>
    <content><![CDATA[<ul>
<li><p>为什么在LLM模型预训练时，计算交叉熵损失函数时需要loss mask</p>
<p>  在自回归训练中，模型需要根据前<span class="math inline">\(n-1\)</span>个Token预测第<span class="math inline">\(n\)</span>个Token。此时，输入序列为<span class="math inline">\(X =
[x_1,x_2,...,x_{n-1}]\)</span>，目标序列为<span class="math inline">\(Y=
[y_1,y_2,...,y_m] \quad m \geq
n\)</span>，掩码规则为仅对目标序列中与当前预测位置匹配的Token计算损失（如第<span class="math inline">\(i\)</span>个预测位置仅计算<span class="math inline">\(y_i\)</span>的损失,其他位置（包括填充Token）设为0，不参与损失计算.
其主要作用如下：</p>
<ul>
<li>忽略无效Token</li>
</ul>
<p>  预训练数据通常包含填充（Padding）标记或特殊符号（如<eos>），这些位置的真实值对模型无意义。若不加掩码，模型会错误学习生成这些无效Token，导致训练效率下降。</eos></p>
<ul>
<li>聚焦有效生成</li>
</ul>
<p>  通过掩码选择性计算损失，模型仅关注实际需要生成的Token（如自回归任务中预测下一个Token），避免被无关信息干扰。</p>
<ul>
<li>保持损失归一化</li>
</ul>
<p>  掩码确保不同批次、不同长度序列的损失计算公平，避免填充Token拉低整体损失值</p></li>
<li><p>深度学习中常用归一化技术</p>
<p>  归一化技术在深度学习中常用于对输入数据进行标准化处理的方法，常见的归一化技术包括：</p>
<ul>
<li><p>Min-Max归一化</p>
<p><span class="math display">\[\bar{x} = \dfrac{x-x_{min}}{x_{max} -
x_{min}}\]</span></p></li>
</ul>
<p>  将数据缩放到<span class="math inline">\([0,1]\)</span>范围，适用于数据分布已知且无异常值的请况。</p>
<ul>
<li><p>Z-Score归一化</p>
<p><span class="math display">\[\bar{x} = \dfrac{x -
\mu}{\delta}\]</span></p></li>
</ul>
<p>  将数据转换为均值为0，标准差为1的分布，适用于数据服从正态分布的情况</p>
<p>  在实际使用中，会针对性的做一些调整以适应不同任务，不同场景，主要有Batch
Norm、Layer Norm、RMS Norm等：</p>
<ul>
<li><p>Batch Norm</p>
<p>  对每个特征通道（如图像的RGB通道）在批量数据上计算均值和方差，通过标准化和平移/缩放参数调整分布，公式如下：
<span class="math display">\[y = \gamma \cdot
\dfrac{x-\mu}{\sqrt{\sigma^2 + \epsilon}} + \beta\]</span></p></li>
<li><p>Layer Norm</p>
<p>  对单个样本的所有特征维度（如序列模型的每个token向量）计算均值和方差，实现跨样本的归一化，公式同上，只是针对的输入不同</p></li>
<li><p>RMS Norm</p>
<p>  LayerNorm的变体，仅计算均方根（RMS）替代均值和方差，去除平移参数<span class="math inline">\(\beta\)</span>，简化计算，公式如下：</p>
<p><span class="math display">\[y = \gamma \cdot
\dfrac{x-\mu}{\sqrt{RMS(x)^2 + \epsilon}}\]</span></p>
<p>其中 <span class="math display">\[RMS(x) = \sqrt{\frac{1}{N}\sum_{i =
1}^Nx_i^2}\]</span></p></li>
</ul>
<p>在深度学习中归一化技术有如下意义：</p>
<ul>
<li><p>提高训练速度</p>
<ul>
<li>归一化可以使不同特征的数值范围相近，避免某些特征值过大或过小，影响梯度更新，导致训练过程缓慢。</li>
<li>通过减少梯度下降的震荡，使优化过程更稳定，加快收敛速度。</li>
</ul></li>
<li><p>防止梯度消失或梯度爆炸</p>
<ul>
<li>归一化可以保持数据分布的稳定性，防止某些层的输入值过大或过小，从而避免梯度消失或梯度爆炸问题，尤其是在深层网络中。</li>
</ul></li>
<li><p>提高模型的泛化能力</p>
<ul>
<li>归一化可以减少特征对不同尺度的依赖，使模型对输入数据的变化更具鲁棒性，提高泛化能力，降低过拟合风险。</li>
</ul></li>
<li><p>减少不同特征之间的影响</p>
<ul>
<li>由于不同特征的尺度不同，模型可能会过度依赖某些大数值特征，导致训练过程不稳定。归一化后，各特征的权重分布更加均衡，提高模型的稳定性。</li>
</ul></li>
</ul>
<p>三类归一化技术对比如下：</p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 30%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr>
<th>方法</th>
<th>典型应用场景</th>
<th>核心优势</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchNorm</td>
<td>图像分类（CNN）、小批量训练场景</td>
<td>加速收敛、降低初始化敏感度</td>
<td>对批量大小敏感，无法处理序列数据（如NLP）</td>
</tr>
<tr>
<td>LayerNorm</td>
<td>自然语言处理（如BERT、GPT）、RNN、长序列模型</td>
<td>适应动态批量、保持序列位置不变性</td>
<td>计算开销较大，对噪声敏感</td>
</tr>
<tr>
<td>RMSNorm</td>
<td>超大规模语言模型（如LLaMA、DeepSeek）、高精度工业检测</td>
<td>计算高效、数值稳定性强、减少梯度爆炸风险</td>
<td>无法处理均值敏感任务（如某些CV任务）</td>
</tr>
</tbody>
</table></li>
</ul>
]]></content>
      <tags>
        <tag>LLM</tag>
        <tag>模型训练</tag>
      </tags>
  </entry>
</search>
